CVE Number : CVE-2015-8104
Commit Message : 
KVM: svm: unconditionally intercept #DB
Commit Details : 
This is needed to avoid the possibility that the guest triggers
an infinite stream of #DB exceptions (CVE-2015-8104).

VMX is not affected: because it does not save DR6 in the VMCS,
it already intercepts #DB unconditionally.

Reported-by: Jan Beulich <jbeulich@suse.com>
Cc: stable@vger.kernel.org
Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

Before patch : 
 	set_exception_intercept(svm, UD_VECTOR);
 	set_exception_intercept(svm, MC_VECTOR);
 	set_exception_intercept(svm, AC_VECTOR);
 
 	set_intercept(svm, INTERCEPT_INTR);
 	set_intercept(svm, INTERCEPT_NMI);
 	mark_dirty(svm >vmcb, VMCB_SEG);
 }
 
 static void update_db_bp_intercept(struct kvm_vcpu *vcpu)
 {
 	struct vcpu_svm *svm = to_svm(vcpu);
 
 	clr_exception_intercept(svm, DB_VECTOR);
 	clr_exception_intercept(svm, BP_VECTOR);
 
 	if (svm >nmi_singlestep)
 		set_exception_intercept(svm, DB_VECTOR);
 
 	if (vcpu >guest_debug & KVM_GUESTDBG_ENABLE) {
 		if (vcpu >guest_debug &
 		    (KVM_GUESTDBG_SINGLESTEP | KVM_GUESTDBG_USE_HW_BP))
 			set_exception_intercept(svm, DB_VECTOR);
 		if (vcpu >guest_debug & KVM_GUESTDBG_USE_SW_BP)
 			set_exception_intercept(svm, BP_VECTOR);
 	} else
 		if (!(svm >vcpu.guest_debug & KVM_GUESTDBG_SINGLESTEP))
 			svm >vmcb >save.rflags &=
 				~(X86_EFLAGS_TF | X86_EFLAGS_RF);
 		update_db_bp_intercept(&svm >vcpu);
 	}
 
 	if (svm >vcpu.guest_debug &
 	 */
 	svm >nmi_singlestep = true;
 	svm >vmcb >save.rflags |= (X86_EFLAGS_TF | X86_EFLAGS_RF);
 	update_db_bp_intercept(vcpu);
 }
 
 static int svm_set_tss_addr(struct kvm *kvm, unsigned int addr)
 	.vcpu_load = svm_vcpu_load,
 	.vcpu_put = svm_vcpu_put,
 
 	.update_db_bp_intercept = update_db_bp_intercept,
 	.get_msr = svm_get_msr,
 	.set_msr = svm_set_msr,
 	.get_segment_base = svm_get_segment_base,
After patch : 
 	set_exception_intercept(svm, UD_VECTOR);
 	set_exception_intercept(svm, MC_VECTOR);
 	set_exception_intercept(svm, AC_VECTOR);
 	set_exception_intercept(svm, DB_VECTOR);
 
 	set_intercept(svm, INTERCEPT_INTR);
 	set_intercept(svm, INTERCEPT_NMI);
 	mark_dirty(svm >vmcb, VMCB_SEG);
 }
 
 static void update_bp_intercept(struct kvm_vcpu *vcpu)
 {
 	struct vcpu_svm *svm = to_svm(vcpu);
 
 	clr_exception_intercept(svm, BP_VECTOR);
 
 	if (vcpu >guest_debug & KVM_GUESTDBG_ENABLE) {
 		if (vcpu >guest_debug & KVM_GUESTDBG_USE_SW_BP)
 			set_exception_intercept(svm, BP_VECTOR);
 	} else
 		if (!(svm >vcpu.guest_debug & KVM_GUESTDBG_SINGLESTEP))
 			svm >vmcb >save.rflags &=
 				~(X86_EFLAGS_TF | X86_EFLAGS_RF);
 	}
 
 	if (svm >vcpu.guest_debug &
 	 */
 	svm >nmi_singlestep = true;
 	svm >vmcb >save.rflags |= (X86_EFLAGS_TF | X86_EFLAGS_RF);
 }
 
 static int svm_set_tss_addr(struct kvm *kvm, unsigned int addr)
 	.vcpu_load = svm_vcpu_load,
 	.vcpu_put = svm_vcpu_put,
 
 	.update_db_bp_intercept = update_bp_intercept,
 	.get_msr = svm_get_msr,
 	.set_msr = svm_set_msr,
 	.get_segment_base = svm_get_segment_base,
