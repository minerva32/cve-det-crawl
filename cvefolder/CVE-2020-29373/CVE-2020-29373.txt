CVE Number : CVE-2020-29373
Commit Message : 
io_uring: grab ->fs as part of async preparation
Commit Details : 
This passes it in to io-wq, so it assumes the right fs_struct when
executing async work that may need to do lookups.

Cc: stable@vger.kernel.org # 5.3+
Signed-off-by: Jens Axboe <axboe@kernel.dk>

Before patch : 
 #include <linux/fsnotify.h>
 #include <linux/fadvise.h>
 #include <linux/eventpoll.h>
 
 #define CREATE_TRACE_POINTS
 #include <trace/events/io_uring.h>
 	unsigned		not_supported : 1;
 	/* needs file table */
 	unsigned		file_table : 1;
 };
 
 static const struct io_op_def io_op_defs[] = {
 		.needs_mm		= 1,
 		.needs_file		= 1,
 		.unbound_nonreg_file	= 1,
 	},
 	[IORING_OP_RECVMSG] = {
 		.async_ctx		= 1,
 		.needs_mm		= 1,
 		.needs_file		= 1,
 		.unbound_nonreg_file	= 1,
 	},
 	[IORING_OP_TIMEOUT] = {
 		.async_ctx		= 1,
 		.needs_file		= 1,
 		.fd_non_neg		= 1,
 		.file_table		= 1,
 	},
 	[IORING_OP_CLOSE] = {
 		.needs_file		= 1,
 		.needs_mm		= 1,
 		.needs_file		= 1,
 		.fd_non_neg		= 1,
 	},
 	[IORING_OP_READ] = {
 		.needs_mm		= 1,
 		.needs_file		= 1,
 		.fd_non_neg		= 1,
 		.file_table		= 1,
 	},
 	[IORING_OP_EPOLL_CTL] = {
 		.unbound_nonreg_file	= 1,
 	}
 	if (!req >work.creds)
 		req >work.creds = get_current_cred();
 }
 
 static inline void io_req_work_drop_env(struct io_kiocb *req)
 		put_cred(req >work.creds);
 		req >work.creds = NULL;
 	}
 }
 
 static inline bool io_prep_async_work(struct io_kiocb *req,
After patch : 
 #include <linux/fsnotify.h>
 #include <linux/fadvise.h>
 #include <linux/eventpoll.h>
 #include <linux/fs_struct.h>
 
 #define CREATE_TRACE_POINTS
 #include <trace/events/io_uring.h>
 	unsigned		not_supported : 1;
 	/* needs file table */
 	unsigned		file_table : 1;
 	/* needs  >fs */
 	unsigned		needs_fs : 1;
 };
 
 static const struct io_op_def io_op_defs[] = {
 		.needs_mm		= 1,
 		.needs_file		= 1,
 		.unbound_nonreg_file	= 1,
 		.needs_fs		= 1,
 	},
 	[IORING_OP_RECVMSG] = {
 		.async_ctx		= 1,
 		.needs_mm		= 1,
 		.needs_file		= 1,
 		.unbound_nonreg_file	= 1,
 		.needs_fs		= 1,
 	},
 	[IORING_OP_TIMEOUT] = {
 		.async_ctx		= 1,
 		.needs_file		= 1,
 		.fd_non_neg		= 1,
 		.file_table		= 1,
 		.needs_fs		= 1,
 	},
 	[IORING_OP_CLOSE] = {
 		.needs_file		= 1,
 		.needs_mm		= 1,
 		.needs_file		= 1,
 		.fd_non_neg		= 1,
 		.needs_fs		= 1,
 	},
 	[IORING_OP_READ] = {
 		.needs_mm		= 1,
 		.needs_file		= 1,
 		.fd_non_neg		= 1,
 		.file_table		= 1,
 		.needs_fs		= 1,
 	},
 	[IORING_OP_EPOLL_CTL] = {
 		.unbound_nonreg_file	= 1,
 	}
 	if (!req >work.creds)
 		req >work.creds = get_current_cred();
 	if (!req >work.fs && def >needs_fs) {
 		spin_lock(&current >fs >lock);
 		if (!current >fs >in_exec) {
 			req >work.fs = current >fs;
 			req >work.fs >users  ;
 		} else {
 			req >work.flags |= IO_WQ_WORK_CANCEL;
 		}
 		spin_unlock(&current >fs >lock);
 	}
 }
 
 static inline void io_req_work_drop_env(struct io_kiocb *req)
 		put_cred(req >work.creds);
 		req >work.creds = NULL;
 	}
 	if (req >work.fs) {
 		struct fs_struct *fs = req >work.fs;
 
 		spin_lock(&req >work.fs >lock);
 		if (  fs >users)
 			fs = NULL;
 		spin_unlock(&req >work.fs >lock);
 		if (fs)
 			free_fs_struct(fs);
 	}
 }
 
 static inline bool io_prep_async_work(struct io_kiocb *req,
