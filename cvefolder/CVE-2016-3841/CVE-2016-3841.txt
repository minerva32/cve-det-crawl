CVE Number : CVE-2016-3841
Commit Message : 
ipv6: add complete rcu protection around np->opt
Commit Details : 
This patch addresses multiple problems :

UDP/RAW sendmsg() need to get a stable struct ipv6_txoptions
while socket is not locked : Other threads can change np->opt
concurrently. Dmitry posted a syzkaller
(http://github.com/google/syzkaller) program desmonstrating
use-after-free.

Starting with TCP/DCCP lockless listeners, tcp_v6_syn_recv_sock()
and dccp_v6_request_recv_sock() also need to use RCU protection
to dereference np->opt once (before calling ipv6_dup_options())

This patch adds full RCU protection to np->opt

Reported-by: Dmitry Vyukov <dvyukov@google.com>
Signed-off-by: Eric Dumazet <edumazet@google.com>
Acked-by: Hannes Frederic Sowa <hannes@stressinduktion.org>
Signed-off-by: David S. Miller <davem@davemloft.net>

Before patch : 
 	struct ipv6_ac_socklist	*ipv6_ac_list;
 	struct ipv6_fl_socklist __rcu *ipv6_fl_list;
 
 	struct ipv6_txoptions	*opt;
 	struct sk_buff		*pktoptions;
 	struct sk_buff		*rxpmtu;
 	struct inet6_cork	cork;
  */
 
 struct ipv6_txoptions {
 	/* Length of this structure */
 	int			tot_len;
 
 	struct ipv6_opt_hdr	*dst0opt;
 	struct ipv6_rt_hdr	*srcrt;	/* Routing Header */
 	struct ipv6_opt_hdr	*dst1opt;
 
 	/* Option buffer, as read by IPV6_PKTOPTIONS, starts here. */
 };
 
 	struct rcu_head			rcu;
 };
 
 struct ip6_flowlabel *fl6_sock_lookup(struct sock *sk, __be32 label);
 struct ipv6_txoptions *fl6_merge_options(struct ipv6_txoptions *opt_space,
 					 struct ip6_flowlabel *fl,
 	security_req_classify_flow(req, flowi6_to_flowi(&fl6));
 
 
 	final_p = fl6_update_dst(&fl6, np >opt, &final);
 
 	dst = ip6_dst_lookup_flow(sk, &fl6, final_p);
 	if (IS_ERR(dst)) {
 							 &ireq >ir_v6_loc_addr,
 							 &ireq >ir_v6_rmt_addr);
 		fl6.daddr = ireq >ir_v6_rmt_addr;
 		err = ip6_xmit(sk, skb, &fl6, np >opt, np >tclass);
 		err = net_xmit_eval(err);
 	}
 
 	struct inet_request_sock *ireq = inet_rsk(req);
 	struct ipv6_pinfo *newnp;
 	const struct ipv6_pinfo *np = inet6_sk(sk);
 	struct inet_sock *newinet;
 	struct dccp6_sock *newdp6;
 	struct sock *newsk;
 	 * Yes, keeping reference count would be much more clever, but we make
 	 * one more one thing there: reattach optmem to newsk.
 	 */
 	if (np >opt != NULL)
 		newnp >opt = ipv6_dup_options(newsk, np >opt);
 
 	inet_csk(newsk) >icsk_ext_hdr_len = 0;
 	if (newnp >opt != NULL)
 		inet_csk(newsk) >icsk_ext_hdr_len = (newnp >opt >opt_nflen  
 						     newnp >opt >opt_flen);
 
 	dccp_sync_mss(newsk, dst_mtu(dst));
 
 	struct ipv6_pinfo *np = inet6_sk(sk);
 	struct dccp_sock *dp = dccp_sk(sk);
 	struct in6_addr *saddr = NULL, *final_p, final;
 	struct flowi6 fl6;
 	struct dst_entry *dst;
 	int addr_type;
 	fl6.fl6_sport = inet >inet_sport;
 	security_sk_classify_flow(sk, flowi6_to_flowi(&fl6));
 
 	final_p = fl6_update_dst(&fl6, np >opt, &final);
 
 	dst = ip6_dst_lookup_flow(sk, &fl6, final_p);
 	if (IS_ERR(dst)) {
 	__ip6_dst_store(sk, dst, NULL, NULL);
 
 	icsk >icsk_ext_hdr_len = 0;
 	if (np >opt != NULL)
 		icsk >icsk_ext_hdr_len = (np >opt >opt_flen  
 					  np >opt >opt_nflen);
 
 	inet >inet_dport = usin >sin6_port;
 
 
 	/* Free tx options */
 
 	opt = xchg(&np >opt, NULL);
 	if (opt)
 		sock_kfree_s(sk, opt, opt >tot_len);
 }
 EXPORT_SYMBOL_GPL(inet6_destroy_sock);
 
 		fl6.fl6_sport = inet >inet_sport;
 		security_sk_classify_flow(sk, flowi6_to_flowi(&fl6));
 
 		final_p = fl6_update_dst(&fl6, np >opt, &final);
 
 		dst = ip6_dst_lookup_flow(sk, &fl6, final_p);
 		if (IS_ERR(dst)) {
 
 	security_sk_classify_flow(sk, flowi6_to_flowi(&fl6));
 
 	opt = flowlabel ? flowlabel >opt : np >opt;
 	final_p = fl6_update_dst(&fl6, opt, &final);
 
 	dst = ip6_dst_lookup_flow(sk, &fl6, final_p);
 	err = 0;
 			*((char **)&opt2 >dst1opt)  = dif;
 		if (opt2 >srcrt)
 			*((char **)&opt2 >srcrt)  = dif;
 	}
 	return opt2;
 }
 		return ERR_PTR( ENOBUFS);
 
 	memset(opt2, 0, tot_len);
 
 	opt2 >tot_len = tot_len;
 	p = (char *)(opt2   1);
 
 	memset(fl6, 0, sizeof(*fl6));
 	fl6 >flowi6_proto = proto;
 	fl6 >daddr = ireq >ir_v6_rmt_addr;
 	final_p = fl6_update_dst(fl6, np >opt, &final);
 	fl6 >saddr = ireq >ir_v6_loc_addr;
 	fl6 >flowi6_oif = ireq >ir_iif;
 	fl6 >flowi6_mark = ireq >ir_mark;
 	fl6 >fl6_dport = inet >inet_dport;
 	security_sk_classify_flow(sk, flowi6_to_flowi(fl6));
 
 	final_p = fl6_update_dst(fl6, np >opt, &final);
 
 	dst = __inet6_csk_dst_check(sk, np >dst_cookie);
 	if (!dst) {
 	/* Restore final destination back after routing done */
 	fl6.daddr = sk >sk_v6_daddr;
 
 	res = ip6_xmit(sk, skb, &fl6, np >opt, np >tclass);
 	rcu_read_unlock();
 	return res;
 }
 			icsk >icsk_sync_mss(sk, icsk >icsk_pmtu_cookie);
 		}
 	}
 	opt = xchg(&inet6_sk(sk) >opt, opt);
 	sk_dst_reset(sk);
 
 	return opt;
 				sk >sk_socket >ops = &inet_dgram_ops;
 				sk >sk_family = PF_INET;
 			}
 			opt = xchg(&np >opt, NULL);
 			if (opt)
 				sock_kfree_s(sk, opt, opt >tot_len);
 			pktopt = xchg(&np >pktoptions, NULL);
 			kfree_skb(pktopt);
 
 		if (optname != IPV6_RTHDR && !ns_capable(net >user_ns, CAP_NET_RAW))
 			break;
 
 		opt = ipv6_renew_options(sk, np >opt, optname,
 					 (struct ipv6_opt_hdr __user *)optval,
 					 optlen);
 		if (IS_ERR(opt)) {
 		retv = 0;
 		opt = ipv6_update_options(sk, opt);
 sticky_done:
 		if (opt)
 			sock_kfree_s(sk, opt, opt >tot_len);
 		break;
 	}
 
 			break;
 
 		memset(opt, 0, sizeof(*opt));
 		opt >tot_len = sizeof(*opt)   optlen;
 		retv =  EFAULT;
 		if (copy_from_user(opt 1, optval, optlen))
 		retv = 0;
 		opt = ipv6_update_options(sk, opt);
 done:
 		if (opt)
 			sock_kfree_s(sk, opt, opt >tot_len);
 		break;
 	}
 	case IPV6_UNICAST_HOPS:
 	case IPV6_RTHDR:
 	case IPV6_DSTOPTS:
 	{
 
 		lock_sock(sk);
 		len = ipv6_getsockopt_sticky(sk, np >opt,
 					     optname, optval, len);
 		release_sock(sk);
 		/* check if ipv6_getsockopt_sticky() returns err code */
 		if (len < 0)
 
 static int rawv6_sendmsg(struct sock *sk, struct msghdr *msg, size_t len)
 {
 	struct ipv6_txoptions opt_space;
 	DECLARE_SOCKADDR(struct sockaddr_in6 *, sin6, msg >msg_name);
 	struct in6_addr *daddr, *final_p, final;
 		if (!(opt >opt_nflen|opt >opt_flen))
 			opt = NULL;
 	}
 	if (!opt)
 		opt = np >opt;
 	if (flowlabel)
 		opt = fl6_merge_options(&opt_space, flowlabel, opt);
 	opt = ipv6_fixup_options(&opt_space, opt);
 	dst_release(dst);
 out:
 	fl6_sock_release(flowlabel);
 	return err < 0 ? err : len;
 do_confirm:
 	dst_confirm(dst);
 		memset(&fl6, 0, sizeof(fl6));
 		fl6.flowi6_proto = IPPROTO_TCP;
 		fl6.daddr = ireq >ir_v6_rmt_addr;
 		final_p = fl6_update_dst(&fl6, np >opt, &final);
 		fl6.saddr = ireq >ir_v6_loc_addr;
 		fl6.flowi6_oif = sk >sk_bound_dev_if;
 		fl6.flowi6_mark = ireq >ir_mark;
 	struct ipv6_pinfo *np = inet6_sk(sk);
 	struct tcp_sock *tp = tcp_sk(sk);
 	struct in6_addr *saddr = NULL, *final_p, final;
 	struct flowi6 fl6;
 	struct dst_entry *dst;
 	int addr_type;
 	fl6.fl6_dport = usin >sin6_port;
 	fl6.fl6_sport = inet >inet_sport;
 
 	final_p = fl6_update_dst(&fl6, np >opt, &final);
 
 	security_sk_classify_flow(sk, flowi6_to_flowi(&fl6));
 
 		tcp_fetch_timewait_stamp(sk, dst);
 
 	icsk >icsk_ext_hdr_len = 0;
 	if (np >opt)
 		icsk >icsk_ext_hdr_len = (np >opt >opt_flen  
 					  np >opt >opt_nflen);
 
 	tp >rx_opt.mss_clamp = IPV6_MIN_MTU   sizeof(struct tcphdr)   sizeof(struct ipv6hdr);
 
 		if (np >repflow && ireq >pktopts)
 			fl6 >flowlabel = ip6_flowlabel(ipv6_hdr(ireq >pktopts));
 
 		err = ip6_xmit(sk, skb, fl6, np >opt, np >tclass);
 		err = net_xmit_eval(err);
 	}
 
 	struct inet_request_sock *ireq;
 	struct ipv6_pinfo *newnp;
 	const struct ipv6_pinfo *np = inet6_sk(sk);
 	struct tcp6_sock *newtcp6sk;
 	struct inet_sock *newinet;
 	struct tcp_sock *newtp;
 	   but we make one more one thing there: reattach optmem
 	   to newsk.
 	 */
 	if (np >opt)
 		newnp >opt = ipv6_dup_options(newsk, np >opt);
 
 	inet_csk(newsk) >icsk_ext_hdr_len = 0;
 	if (newnp >opt)
 		inet_csk(newsk) >icsk_ext_hdr_len = (newnp >opt >opt_nflen  
 						     newnp >opt >opt_flen);
 
 	tcp_ca_openreq_child(newsk, dst);
 
 	DECLARE_SOCKADDR(struct sockaddr_in6 *, sin6, msg >msg_name);
 	struct in6_addr *daddr, *final_p, final;
 	struct ipv6_txoptions *opt = NULL;
 	struct ip6_flowlabel *flowlabel = NULL;
 	struct flowi6 fl6;
 	struct dst_entry *dst;
 			opt = NULL;
 		connected = 0;
 	}
 	if (!opt)
 		opt = np >opt;
 	if (flowlabel)
 		opt = fl6_merge_options(&opt_space, flowlabel, opt);
 	opt = ipv6_fixup_options(&opt_space, opt);
 out:
 	dst_release(dst);
 	fl6_sock_release(flowlabel);
 	if (!err)
 		return len;
 	/*
 	DECLARE_SOCKADDR(struct sockaddr_l2tpip6 *, lsa, msg >msg_name);
 	struct in6_addr *daddr, *final_p, final;
 	struct ipv6_pinfo *np = inet6_sk(sk);
 	struct ipv6_txoptions *opt = NULL;
 	struct ip6_flowlabel *flowlabel = NULL;
 	struct dst_entry *dst = NULL;
 			opt = NULL;
 	}
 
 	if (opt == NULL)
 		opt = np >opt;
 	if (flowlabel)
 		opt = fl6_merge_options(&opt_space, flowlabel, opt);
 	opt = ipv6_fixup_options(&opt_space, opt);
 	dst_release(dst);
 out:
 	fl6_sock_release(flowlabel);
 
 	return err < 0 ? err : len;
 
After patch : 
 	struct ipv6_ac_socklist	*ipv6_ac_list;
 	struct ipv6_fl_socklist __rcu *ipv6_fl_list;
 
 	struct ipv6_txoptions __rcu	*opt;
 	struct sk_buff		*pktoptions;
 	struct sk_buff		*rxpmtu;
 	struct inet6_cork	cork;
  */
 
 struct ipv6_txoptions {
 	atomic_t		refcnt;
 	/* Length of this structure */
 	int			tot_len;
 
 	struct ipv6_opt_hdr	*dst0opt;
 	struct ipv6_rt_hdr	*srcrt;	/* Routing Header */
 	struct ipv6_opt_hdr	*dst1opt;
 	struct rcu_head		rcu;
 	/* Option buffer, as read by IPV6_PKTOPTIONS, starts here. */
 };
 
 	struct rcu_head			rcu;
 };
 
 static inline struct ipv6_txoptions *txopt_get(const struct ipv6_pinfo *np)
 {
 	struct ipv6_txoptions *opt;
 
 	rcu_read_lock();
 	opt = rcu_dereference(np >opt);
 	if (opt && !atomic_inc_not_zero(&opt >refcnt))
 		opt = NULL;
 	rcu_read_unlock();
 	return opt;
 }
 
 static inline void txopt_put(struct ipv6_txoptions *opt)
 {
 	if (opt && atomic_dec_and_test(&opt >refcnt))
 		kfree_rcu(opt, rcu);
 }
 
 struct ip6_flowlabel *fl6_sock_lookup(struct sock *sk, __be32 label);
 struct ipv6_txoptions *fl6_merge_options(struct ipv6_txoptions *opt_space,
 					 struct ip6_flowlabel *fl,
 	security_req_classify_flow(req, flowi6_to_flowi(&fl6));
 
 
 	rcu_read_lock();
 	final_p = fl6_update_dst(&fl6, rcu_dereference(np >opt), &final);
 	rcu_read_unlock();
 
 	dst = ip6_dst_lookup_flow(sk, &fl6, final_p);
 	if (IS_ERR(dst)) {
 							 &ireq >ir_v6_loc_addr,
 							 &ireq >ir_v6_rmt_addr);
 		fl6.daddr = ireq >ir_v6_rmt_addr;
 		rcu_read_lock();
 		err = ip6_xmit(sk, skb, &fl6, rcu_dereference(np >opt),
 			       np >tclass);
 		rcu_read_unlock();
 		err = net_xmit_eval(err);
 	}
 
 	struct inet_request_sock *ireq = inet_rsk(req);
 	struct ipv6_pinfo *newnp;
 	const struct ipv6_pinfo *np = inet6_sk(sk);
 	struct ipv6_txoptions *opt;
 	struct inet_sock *newinet;
 	struct dccp6_sock *newdp6;
 	struct sock *newsk;
 	 * Yes, keeping reference count would be much more clever, but we make
 	 * one more one thing there: reattach optmem to newsk.
 	 */
 	opt = rcu_dereference(np >opt);
 	if (opt) {
 		opt = ipv6_dup_options(newsk, opt);
 		RCU_INIT_POINTER(newnp >opt, opt);
 	}
 	inet_csk(newsk) >icsk_ext_hdr_len = 0;
 	if (opt)
 		inet_csk(newsk) >icsk_ext_hdr_len = opt >opt_nflen  
 						    opt >opt_flen;
 
 	dccp_sync_mss(newsk, dst_mtu(dst));
 
 	struct ipv6_pinfo *np = inet6_sk(sk);
 	struct dccp_sock *dp = dccp_sk(sk);
 	struct in6_addr *saddr = NULL, *final_p, final;
 	struct ipv6_txoptions *opt;
 	struct flowi6 fl6;
 	struct dst_entry *dst;
 	int addr_type;
 	fl6.fl6_sport = inet >inet_sport;
 	security_sk_classify_flow(sk, flowi6_to_flowi(&fl6));
 
 	opt = rcu_dereference_protected(np >opt, sock_owned_by_user(sk));
 	final_p = fl6_update_dst(&fl6, opt, &final);
 
 	dst = ip6_dst_lookup_flow(sk, &fl6, final_p);
 	if (IS_ERR(dst)) {
 	__ip6_dst_store(sk, dst, NULL, NULL);
 
 	icsk >icsk_ext_hdr_len = 0;
 	if (opt)
 		icsk >icsk_ext_hdr_len = opt >opt_flen   opt >opt_nflen;
 
 	inet >inet_dport = usin >sin6_port;
 
 
 	/* Free tx options */
 
 	opt = xchg((__force struct ipv6_txoptions **)&np >opt, NULL);
 	if (opt) {
 		atomic_sub(opt >tot_len, &sk >sk_omem_alloc);
 		txopt_put(opt);
 	}
 }
 EXPORT_SYMBOL_GPL(inet6_destroy_sock);
 
 		fl6.fl6_sport = inet >inet_sport;
 		security_sk_classify_flow(sk, flowi6_to_flowi(&fl6));
 
 		rcu_read_lock();
 		final_p = fl6_update_dst(&fl6, rcu_dereference(np >opt),
 					 &final);
 		rcu_read_unlock();
 
 		dst = ip6_dst_lookup_flow(sk, &fl6, final_p);
 		if (IS_ERR(dst)) {
 
 	security_sk_classify_flow(sk, flowi6_to_flowi(&fl6));
 
 	rcu_read_lock();
 	opt = flowlabel ? flowlabel >opt : rcu_dereference(np >opt);
 	final_p = fl6_update_dst(&fl6, opt, &final);
 	rcu_read_unlock();
 
 	dst = ip6_dst_lookup_flow(sk, &fl6, final_p);
 	err = 0;
 			*((char **)&opt2 >dst1opt)  = dif;
 		if (opt2 >srcrt)
 			*((char **)&opt2 >srcrt)  = dif;
 		atomic_set(&opt2 >refcnt, 1);
 	}
 	return opt2;
 }
 		return ERR_PTR( ENOBUFS);
 
 	memset(opt2, 0, tot_len);
 	atomic_set(&opt2 >refcnt, 1);
 	opt2 >tot_len = tot_len;
 	p = (char *)(opt2   1);
 
 	memset(fl6, 0, sizeof(*fl6));
 	fl6 >flowi6_proto = proto;
 	fl6 >daddr = ireq >ir_v6_rmt_addr;
 	rcu_read_lock();
 	final_p = fl6_update_dst(fl6, rcu_dereference(np >opt), &final);
 	rcu_read_unlock();
 	fl6 >saddr = ireq >ir_v6_loc_addr;
 	fl6 >flowi6_oif = ireq >ir_iif;
 	fl6 >flowi6_mark = ireq >ir_mark;
 	fl6 >fl6_dport = inet >inet_dport;
 	security_sk_classify_flow(sk, flowi6_to_flowi(fl6));
 
 	rcu_read_lock();
 	final_p = fl6_update_dst(fl6, rcu_dereference(np >opt), &final);
 	rcu_read_unlock();
 
 	dst = __inet6_csk_dst_check(sk, np >dst_cookie);
 	if (!dst) {
 	/* Restore final destination back after routing done */
 	fl6.daddr = sk >sk_v6_daddr;
 
 	res = ip6_xmit(sk, skb, &fl6, rcu_dereference(np >opt),
 		       np >tclass);
 	rcu_read_unlock();
 	return res;
 }
 			icsk >icsk_sync_mss(sk, icsk >icsk_pmtu_cookie);
 		}
 	}
 	opt = xchg((__force struct ipv6_txoptions **)&inet6_sk(sk) >opt,
 		   opt);
 	sk_dst_reset(sk);
 
 	return opt;
 				sk >sk_socket >ops = &inet_dgram_ops;
 				sk >sk_family = PF_INET;
 			}
 			opt = xchg((__force struct ipv6_txoptions **)&np >opt,
 				   NULL);
 			if (opt) {
 				atomic_sub(opt >tot_len, &sk >sk_omem_alloc);
 				txopt_put(opt);
 			}
 			pktopt = xchg(&np >pktoptions, NULL);
 			kfree_skb(pktopt);
 
 		if (optname != IPV6_RTHDR && !ns_capable(net >user_ns, CAP_NET_RAW))
 			break;
 
 		opt = rcu_dereference_protected(np >opt, sock_owned_by_user(sk));
 		opt = ipv6_renew_options(sk, opt, optname,
 					 (struct ipv6_opt_hdr __user *)optval,
 					 optlen);
 		if (IS_ERR(opt)) {
 		retv = 0;
 		opt = ipv6_update_options(sk, opt);
 sticky_done:
 		if (opt) {
 			atomic_sub(opt >tot_len, &sk >sk_omem_alloc);
 			txopt_put(opt);
 		}
 		break;
 	}
 
 			break;
 
 		memset(opt, 0, sizeof(*opt));
 		atomic_set(&opt >refcnt, 1);
 		opt >tot_len = sizeof(*opt)   optlen;
 		retv =  EFAULT;
 		if (copy_from_user(opt 1, optval, optlen))
 		retv = 0;
 		opt = ipv6_update_options(sk, opt);
 done:
 		if (opt) {
 			atomic_sub(opt >tot_len, &sk >sk_omem_alloc);
 			txopt_put(opt);
 		}
 		break;
 	}
 	case IPV6_UNICAST_HOPS:
 	case IPV6_RTHDR:
 	case IPV6_DSTOPTS:
 	{
 		struct ipv6_txoptions *opt;
 
 		lock_sock(sk);
 		opt = rcu_dereference_protected(np >opt, sock_owned_by_user(sk));
 		len = ipv6_getsockopt_sticky(sk, opt, optname, optval, len);
 		release_sock(sk);
 		/* check if ipv6_getsockopt_sticky() returns err code */
 		if (len < 0)
 
 static int rawv6_sendmsg(struct sock *sk, struct msghdr *msg, size_t len)
 {
 	struct ipv6_txoptions *opt_to_free = NULL;
 	struct ipv6_txoptions opt_space;
 	DECLARE_SOCKADDR(struct sockaddr_in6 *, sin6, msg >msg_name);
 	struct in6_addr *daddr, *final_p, final;
 		if (!(opt >opt_nflen|opt >opt_flen))
 			opt = NULL;
 	}
 	if (!opt) {
 		opt = txopt_get(np);
 		opt_to_free = opt;
 		}
 	if (flowlabel)
 		opt = fl6_merge_options(&opt_space, flowlabel, opt);
 	opt = ipv6_fixup_options(&opt_space, opt);
 	dst_release(dst);
 out:
 	fl6_sock_release(flowlabel);
 	txopt_put(opt_to_free);
 	return err < 0 ? err : len;
 do_confirm:
 	dst_confirm(dst);
 		memset(&fl6, 0, sizeof(fl6));
 		fl6.flowi6_proto = IPPROTO_TCP;
 		fl6.daddr = ireq >ir_v6_rmt_addr;
 		final_p = fl6_update_dst(&fl6, rcu_dereference(np >opt), &final);
 		fl6.saddr = ireq >ir_v6_loc_addr;
 		fl6.flowi6_oif = sk >sk_bound_dev_if;
 		fl6.flowi6_mark = ireq >ir_mark;
 	struct ipv6_pinfo *np = inet6_sk(sk);
 	struct tcp_sock *tp = tcp_sk(sk);
 	struct in6_addr *saddr = NULL, *final_p, final;
 	struct ipv6_txoptions *opt;
 	struct flowi6 fl6;
 	struct dst_entry *dst;
 	int addr_type;
 	fl6.fl6_dport = usin >sin6_port;
 	fl6.fl6_sport = inet >inet_sport;
 
 	opt = rcu_dereference_protected(np >opt, sock_owned_by_user(sk));
 	final_p = fl6_update_dst(&fl6, opt, &final);
 
 	security_sk_classify_flow(sk, flowi6_to_flowi(&fl6));
 
 		tcp_fetch_timewait_stamp(sk, dst);
 
 	icsk >icsk_ext_hdr_len = 0;
 	if (opt)
 		icsk >icsk_ext_hdr_len = opt >opt_flen  
 					 opt >opt_nflen;
 
 	tp >rx_opt.mss_clamp = IPV6_MIN_MTU   sizeof(struct tcphdr)   sizeof(struct ipv6hdr);
 
 		if (np >repflow && ireq >pktopts)
 			fl6 >flowlabel = ip6_flowlabel(ipv6_hdr(ireq >pktopts));
 
 		err = ip6_xmit(sk, skb, fl6, rcu_dereference(np >opt),
 			       np >tclass);
 		err = net_xmit_eval(err);
 	}
 
 	struct inet_request_sock *ireq;
 	struct ipv6_pinfo *newnp;
 	const struct ipv6_pinfo *np = inet6_sk(sk);
 	struct ipv6_txoptions *opt;
 	struct tcp6_sock *newtcp6sk;
 	struct inet_sock *newinet;
 	struct tcp_sock *newtp;
 	   but we make one more one thing there: reattach optmem
 	   to newsk.
 	 */
 	opt = rcu_dereference(np >opt);
 	if (opt) {
 		opt = ipv6_dup_options(newsk, opt);
 		RCU_INIT_POINTER(newnp >opt, opt);
 	}
 	inet_csk(newsk) >icsk_ext_hdr_len = 0;
 	if (opt)
 		inet_csk(newsk) >icsk_ext_hdr_len = opt >opt_nflen  
 						    opt >opt_flen;
 
 	tcp_ca_openreq_child(newsk, dst);
 
 	DECLARE_SOCKADDR(struct sockaddr_in6 *, sin6, msg >msg_name);
 	struct in6_addr *daddr, *final_p, final;
 	struct ipv6_txoptions *opt = NULL;
 	struct ipv6_txoptions *opt_to_free = NULL;
 	struct ip6_flowlabel *flowlabel = NULL;
 	struct flowi6 fl6;
 	struct dst_entry *dst;
 			opt = NULL;
 		connected = 0;
 	}
 	if (!opt) {
 		opt = txopt_get(np);
 		opt_to_free = opt;
 	}
 	if (flowlabel)
 		opt = fl6_merge_options(&opt_space, flowlabel, opt);
 	opt = ipv6_fixup_options(&opt_space, opt);
 out:
 	dst_release(dst);
 	fl6_sock_release(flowlabel);
 	txopt_put(opt_to_free);
 	if (!err)
 		return len;
 	/*
 	DECLARE_SOCKADDR(struct sockaddr_l2tpip6 *, lsa, msg >msg_name);
 	struct in6_addr *daddr, *final_p, final;
 	struct ipv6_pinfo *np = inet6_sk(sk);
 	struct ipv6_txoptions *opt_to_free = NULL;
 	struct ipv6_txoptions *opt = NULL;
 	struct ip6_flowlabel *flowlabel = NULL;
 	struct dst_entry *dst = NULL;
 			opt = NULL;
 	}
 
 	if (!opt) {
 		opt = txopt_get(np);
 		opt_to_free = opt;
 	}
 	if (flowlabel)
 		opt = fl6_merge_options(&opt_space, flowlabel, opt);
 	opt = ipv6_fixup_options(&opt_space, opt);
 	dst_release(dst);
 out:
 	fl6_sock_release(flowlabel);
 	txopt_put(opt_to_free);
 
 	return err < 0 ? err : len;
 
