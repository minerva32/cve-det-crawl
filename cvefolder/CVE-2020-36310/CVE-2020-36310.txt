CVE Number : CVE-2020-36310
Commit Message : 
KVM: SVM: avoid infinite loop on NPF from bad address
Commit Details : 
When a nested page fault is taken from an address that does not have
a memslot associated to it, kvm_mmu_do_page_fault returns RET_PF_EMULATE
(via mmu_set_spte) and kvm_mmu_page_fault then invokes svm_need_emulation_on_page_fault.

The default answer there is to return false, but in this case this just
causes the page fault to be retried ad libitum.  Since this is not a
fast path, and the only other case where it is taken is an erratum,
just stick a kvm_vcpu_gfn_to_memslot check in there to detect the
common case where the erratum is not happening.

This fixes an infinite loop in the new set_memory_region_test.

Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

Before patch : 
 	bool is_user = svm_get_cpl(vcpu) == 3;
 
 	/*
 	 * Detect and workaround Errata 1096 Fam_17h_00_0Fh.
 	 *
 	 * Errata:
 {
 	return __gfn_to_memslot(kvm_vcpu_memslots(vcpu), gfn);
 }
 
 bool kvm_is_visible_gfn(struct kvm *kvm, gfn_t gfn)
 {
After patch : 
 	bool is_user = svm_get_cpl(vcpu) == 3;
 
 	/*
 	 * If RIP is invalid, go ahead with emulation which will cause an
 	 * internal error exit.
 	 */
 	if (!kvm_vcpu_gfn_to_memslot(vcpu, kvm_rip_read(vcpu) >> PAGE_SHIFT))
 		return true;
 
 	/*
 	 * Detect and workaround Errata 1096 Fam_17h_00_0Fh.
 	 *
 	 * Errata:
 {
 	return __gfn_to_memslot(kvm_vcpu_memslots(vcpu), gfn);
 }
 EXPORT_SYMBOL_GPL(kvm_vcpu_gfn_to_memslot);
 
 bool kvm_is_visible_gfn(struct kvm *kvm, gfn_t gfn)
 {
