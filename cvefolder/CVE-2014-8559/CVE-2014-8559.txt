CVE Number : CVE-2014-8559
Commit Message : 
move d_rcu from overlapping d_child to overlapping d_alias
Commit Details : 
Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

Before patch : 
 	struct dentry *dentry, *tmp;
 
 	mutex_lock(&dir >d_inode >i_mutex);
 	list_for_each_entry_safe(dentry, tmp, &dir >d_subdirs, d_u.d_child) {
 		spin_lock(&dentry >d_lock);
 		if (!(d_unhashed(dentry)) && dentry >d_inode) {
 			dget_dlock(dentry);
 	       inode >i_ino, inode >i_generation, inode);
 
 	ll_lock_dcache(inode);
 	ll_d_hlist_for_each_entry(dentry, p, &inode >i_dentry, d_alias) {
 		CDEBUG(D_DENTRY, "dentry in drop %.*s (%p) parent %p "
 		       "inode %p flags %d\n", dentry >d_name.len,
 		       dentry >d_name.name, dentry, dentry >d_parent,
 		return;
 
 	list_for_each(tmp, &dentry >d_subdirs) {
 		struct dentry *d = list_entry(tmp, struct dentry, d_u.d_child);
 		lustre_dump_dentry(d, recur   1);
 	}
 }
 	struct ll_d_hlist_node *p;
 
 	ll_lock_dcache(dir);
 	ll_d_hlist_for_each_entry(dentry, p, &dir >i_dentry, d_alias) {
 		spin_lock(&dentry >d_lock);
 		if (!list_empty(&dentry >d_subdirs)) {
 			struct dentry *child;
 
 			list_for_each_entry_safe(child, tmp_subdir,
 						 &dentry >d_subdirs,
 						 d_u.d_child) {
 				if (child >d_inode == NULL)
 					d_lustre_invalidate(child, 1);
 			}
 	discon_alias = invalid_alias = NULL;
 
 	ll_lock_dcache(inode);
 	ll_d_hlist_for_each_entry(alias, p, &inode >i_dentry, d_alias) {
 		LASSERT(alias != dentry);
 
 		spin_lock(&alias >d_lock);
 {
 	struct dentry *parent, *child;
 
 	parent = ll_d_hlist_entry(dir >i_dentry, struct dentry, d_alias);
 	child = d_lookup(parent, name);
 	if (child) {
 		if (child >d_inode)
 {
 	struct dentry *dentry;
 	spin_lock(&inode >i_lock);
 	hlist_for_each_entry(dentry, &inode >i_dentry, d_alias) {
 		if (entry_ino == (u32)(long)dentry >d_fsdata) {
 			dentry >d_fsdata = (void *)inode >i_ino;
 			break;
 	spin_lock(&root >d_lock);
 
 	if (prev)
 		next = prev >d_u.d_child.next;
 	else {
 		prev = dget_dlock(root);
 		next = prev >d_subdirs.next;
 		return NULL;
 	}
 
 	q = list_entry(next, struct dentry, d_u.d_child);
 
 	spin_lock_nested(&q >d_lock, DENTRY_D_LOCK_NESTED);
 	/* Already gone or negative dentry (under construction)   try next */
 	if (!d_count(q) || !simple_positive(q)) {
 		spin_unlock(&q >d_lock);
 		next = q >d_u.d_child.next;
 		goto cont;
 	}
 	dget_dlock(q);
 				goto relock;
 			}
 			spin_unlock(&p >d_lock);
 			next = p >d_u.d_child.next;
 			p = parent;
 			if (next != &parent >d_subdirs)
 				break;
 		}
 	}
 	ret = list_entry(next, struct dentry, d_u.d_child);
 
 	spin_lock_nested(&ret >d_lock, DENTRY_D_LOCK_NESTED);
 	/* Negative dentry   try next */
 	spin_lock(&sbi >lookup_lock);
 	spin_lock(&expired >d_parent >d_lock);
 	spin_lock_nested(&expired >d_lock, DENTRY_D_LOCK_NESTED);
 	list_move(&expired >d_parent >d_subdirs, &expired >d_u.d_child);
 	spin_unlock(&expired >d_lock);
 	spin_unlock(&expired >d_parent >d_lock);
 	spin_unlock(&sbi >lookup_lock);
 	/* only consider parents below dentrys in the root */
 	if (IS_ROOT(parent >d_parent))
 		return;
 	d_child = &dentry >d_u.d_child;
 	/* Set parent managed if it's becoming empty */
 	if (d_child >next == &parent >d_subdirs &&
 	    d_child >prev == &parent >d_subdirs)
 /*
  * When possible, we try to satisfy a readdir by peeking at the
  * dcache.  We make this work by carefully ordering dentries on
  * d_u.d_child when we initially get results back from the MDS, and
  * falling back to a "normal" sync readdir if any dentries in the dir
  * are dropped.
  *
 		p = parent >d_subdirs.prev;
 		dout(" initial p %p/%p\n", p >prev, p >next);
 	} else {
 		p = last >d_u.d_child.prev;
 	}
 
 more:
 	dentry = list_entry(p, struct dentry, d_u.d_child);
 	di = ceph_dentry(dentry);
 	while (1) {
 		dout(" p %p/%p %s d_subdirs %p/%p\n", p >prev, p >next,
 		     !dentry >d_inode ? " null" : "");
 		spin_unlock(&dentry >d_lock);
 		p = p >prev;
 		dentry = list_entry(p, struct dentry, d_u.d_child);
 		di = ceph_dentry(dentry);
 	}
 
 			/* reorder parent's d_subdirs */
 			spin_lock(&parent >d_lock);
 			spin_lock_nested(&dn >d_lock, DENTRY_D_LOCK_NESTED);
 			list_move(&dn >d_u.d_child, &parent >d_subdirs);
 			spin_unlock(&dn >d_lock);
 			spin_unlock(&parent >d_lock);
 		}
 	struct dentry *dentry;
 
 	spin_lock(&inode >i_lock);
 	hlist_for_each_entry(dentry, &inode >i_dentry, d_alias) {
 		if (!d_unhashed(dentry) || IS_ROOT(dentry)) {
 			spin_unlock(&inode >i_lock);
 			return true;
 	struct dentry *de;
 
 	spin_lock(&parent >d_lock);
 	list_for_each_entry(de, &parent >d_subdirs, d_u.d_child) {
 		/* don't know what to do with negative dentries */
 		if (de >d_inode ) 
 			coda_flag_inode(de >d_inode, flag);
 /*
  * Usage:
  * dcache >d_inode >i_lock protects:
  *     i_dentry, d_alias, d_inode of aliases
  * dcache_hash_bucket lock protects:
  *     the dcache hash table
  * s_anon bl list spinlock protects:
  *     d_unhashed()
  *     d_parent and d_subdirs
  *     childrens' d_child and d_parent
  *     d_alias, d_inode
  *
  * Ordering:
  * dentry >d_inode >i_lock
 {
 	struct dentry *dentry = container_of(head, struct dentry, d_u.d_rcu);
 
 	WARN_ON(!hlist_unhashed(&dentry >d_alias));
 	kmem_cache_free(dentry_cache, dentry); 
 }
 
 static void __d_free_external(struct rcu_head *head)
 {
 	struct dentry *dentry = container_of(head, struct dentry, d_u.d_rcu);
 	WARN_ON(!hlist_unhashed(&dentry >d_alias));
 	kfree(external_name(dentry));
 	kmem_cache_free(dentry_cache, dentry); 
 }
 
 static void dentry_free(struct dentry *dentry)
 {
 	if (unlikely(dname_external(dentry))) {
 		struct external_name *p = external_name(dentry);
 		if (likely(atomic_dec_and_test(&p >u.count))) {
 	struct inode *inode = dentry >d_inode;
 	if (inode) {
 		dentry >d_inode = NULL;
 		hlist_del_init(&dentry >d_alias);
 		spin_unlock(&dentry >d_lock);
 		spin_unlock(&inode >i_lock);
 		if (!inode >i_nlink)
 	struct inode *inode = dentry >d_inode;
 	__d_clear_type(dentry);
 	dentry >d_inode = NULL;
 	hlist_del_init(&dentry >d_alias);
 	dentry_rcuwalk_barrier(dentry);
 	spin_unlock(&dentry >d_lock);
 	spin_unlock(&inode >i_lock);
 	}
 	/* if it was on the hash then remove it */
 	__d_drop(dentry);
 	list_del(&dentry >d_u.d_child);
 	/*
 	 * Inform d_walk() that we are no longer attached to the
 	 * dentry tree
 
 again:
 	discon_alias = NULL;
 	hlist_for_each_entry(alias, &inode >i_dentry, d_alias) {
 		spin_lock(&alias >d_lock);
  		if (S_ISDIR(inode >i_mode) || !d_unhashed(alias)) {
 			if (IS_ROOT(alias) &&
 	struct dentry *dentry;
 restart:
 	spin_lock(&inode >i_lock);
 	hlist_for_each_entry(dentry, &inode >i_dentry, d_alias) {
 		spin_lock(&dentry >d_lock);
 		if (!dentry >d_lockref.count) {
 			struct dentry *parent = lock_parent(dentry);
 resume:
 	while (next != &this_parent >d_subdirs) {
 		struct list_head *tmp = next;
 		struct dentry *dentry = list_entry(tmp, struct dentry, d_u.d_child);
 		next = tmp >next;
 
 		spin_lock_nested(&dentry >d_lock, DENTRY_D_LOCK_NESTED);
 			goto rename_retry;
 		}
 		rcu_read_unlock();
 		next = child >d_u.d_child.next;
 		goto resume;
 	}
 	if (need_seqretry(&rename_lock, seq)) {
 	INIT_HLIST_BL_NODE(&dentry >d_hash);
 	INIT_LIST_HEAD(&dentry >d_lru);
 	INIT_LIST_HEAD(&dentry >d_subdirs);
 	INIT_HLIST_NODE(&dentry >d_alias);
 	INIT_LIST_HEAD(&dentry >d_u.d_child);
 	d_set_d_op(dentry, dentry >d_sb >s_d_op);
 
 	this_cpu_inc(nr_dentry);
 	 */
 	__dget_dlock(parent);
 	dentry >d_parent = parent;
 	list_add(&dentry >d_u.d_child, &parent >d_subdirs);
 	spin_unlock(&parent >d_lock);
 
 	return dentry;
 	spin_lock(&dentry >d_lock);
 	__d_set_type(dentry, add_flags);
 	if (inode)
 		hlist_add_head(&dentry >d_alias, &inode >i_dentry);
 	dentry >d_inode = inode;
 	dentry_rcuwalk_barrier(dentry);
 	spin_unlock(&dentry >d_lock);
 
 void d_instantiate(struct dentry *entry, struct inode * inode)
 {
 	BUG_ON(!hlist_unhashed(&entry >d_alias));
 	if (inode)
 		spin_lock(&inode >i_lock);
 	__d_instantiate(entry, inode);
 		return NULL;
 	}
 
 	hlist_for_each_entry(alias, &inode >i_dentry, d_alias) {
 		/*
 		 * Don't need alias >d_lock here, because aliases with
 		 * d_parent == entry >d_parent are not subject to name or
 {
 	struct dentry *result;
 
 	BUG_ON(!hlist_unhashed(&entry >d_alias));
 
 	if (inode)
 		spin_lock(&inode >i_lock);
  */
 int d_instantiate_no_diralias(struct dentry *entry, struct inode *inode)
 {
 	BUG_ON(!hlist_unhashed(&entry >d_alias));
 
 	spin_lock(&inode >i_lock);
 	if (S_ISDIR(inode >i_mode) && !hlist_empty(&inode >i_dentry)) {
 
 	if (hlist_empty(&inode >i_dentry))
 		return NULL;
 	alias = hlist_entry(inode >i_dentry.first, struct dentry, d_alias);
 	__dget(alias);
 	return alias;
 }
 	spin_lock(&tmp >d_lock);
 	tmp >d_inode = inode;
 	tmp >d_flags |= add_flags;
 	hlist_add_head(&tmp >d_alias, &inode >i_dentry);
 	hlist_bl_lock(&tmp >d_sb >s_anon);
 	hlist_bl_add_head(&tmp >d_hash, &tmp >d_sb >s_anon);
 	hlist_bl_unlock(&tmp >d_sb >s_anon);
 	struct dentry *child;
 
 	spin_lock(&dparent >d_lock);
 	list_for_each_entry(child, &dparent >d_subdirs, d_u.d_child) {
 		if (dentry == child) {
 			spin_lock_nested(&dentry >d_lock, DENTRY_D_LOCK_NESTED);
 			__dget_dlock(dentry);
 		/* splicing a tree */
 		dentry >d_parent = target >d_parent;
 		target >d_parent = target;
 		list_del_init(&target >d_u.d_child);
 		list_move(&dentry >d_u.d_child, &dentry >d_parent >d_subdirs);
 	} else {
 		/* swapping two dentries */
 		swap(dentry >d_parent, target >d_parent);
 		list_move(&target >d_u.d_child, &target >d_parent >d_subdirs);
 		list_move(&dentry >d_u.d_child, &dentry >d_parent >d_subdirs);
 		if (exchange)
 			fsnotify_d_move(target);
 		fsnotify_d_move(dentry);
 {
 	inode_dec_link_count(inode);
 	BUG_ON(dentry >d_name.name != dentry >d_iname ||
 		!hlist_unhashed(&dentry >d_alias) ||
 		!d_unlinked(dentry));
 	spin_lock(&dentry >d_parent >d_lock);
 	spin_lock_nested(&dentry >d_lock, DENTRY_D_LOCK_NESTED);
 	 * use the d_u.d_child as the rcu head and corrupt this list.
 	 */
 	spin_lock(&parent >d_lock);
 	list_for_each_entry(child, &parent >d_subdirs, d_u.d_child) {
 		if (!debugfs_positive(child))
 			continue;
 
 
 	inode = result >d_inode;
 	spin_lock(&inode >i_lock);
 	hlist_for_each_entry(dentry, &inode >i_dentry, d_alias) {
 		dget(dentry);
 		spin_unlock(&inode >i_lock);
 		if (toput)
 
 			spin_lock(&dentry >d_lock);
 			/* d_lock not required for cursor */
 			list_del(&cursor >d_u.d_child);
 			p = dentry >d_subdirs.next;
 			while (n && p != &dentry >d_subdirs) {
 				struct dentry *next;
 				next = list_entry(p, struct dentry, d_u.d_child);
 				spin_lock_nested(&next >d_lock, DENTRY_D_LOCK_NESTED);
 				if (simple_positive(next))
 					n  ;
 				spin_unlock(&next >d_lock);
 				p = p >next;
 			}
 			list_add_tail(&cursor >d_u.d_child, p);
 			spin_unlock(&dentry >d_lock);
 		}
 	}
 {
 	struct dentry *dentry = file >f_path.dentry;
 	struct dentry *cursor = file >private_data;
 	struct list_head *p, *q = &cursor >d_u.d_child;
 
 	if (!dir_emit_dots(file, ctx))
 		return 0;
 		list_move(q, &dentry >d_subdirs);
 
 	for (p = q >next; p != &dentry >d_subdirs; p = p >next) {
 		struct dentry *next = list_entry(p, struct dentry, d_u.d_child);
 		spin_lock_nested(&next >d_lock, DENTRY_D_LOCK_NESTED);
 		if (!simple_positive(next)) {
 			spin_unlock(&next >d_lock);
 	int ret = 0;
 
 	spin_lock(&dentry >d_lock);
 	list_for_each_entry(child, &dentry >d_subdirs, d_u.d_child) {
 		spin_lock_nested(&child >d_lock, DENTRY_D_LOCK_NESTED);
 		if (simple_positive(child)) {
 			spin_unlock(&child >d_lock);
 
 	/* If a pointer is invalid, we search the dentry. */
 	spin_lock(&parent >d_lock);
 	list_for_each_entry(dent, &parent >d_subdirs, d_u.d_child) {
 		if ((unsigned long)dent >d_fsdata == fpos) {
 			if (dent >d_inode)
 				dget(dent);
 	struct dentry *dentry;
 
 	spin_lock(&parent >d_lock);
 	list_for_each_entry(dentry, &parent >d_subdirs, d_u.d_child) {
 		if (dentry >d_fsdata == NULL)
 			ncp_age_dentry(server, dentry);
 		else
 	struct dentry *dentry;
 
 	spin_lock(&parent >d_lock);
 	list_for_each_entry(dentry, &parent >d_subdirs, d_u.d_child) {
 		dentry >d_fsdata = NULL;
 		ncp_age_dentry(server, dentry);
 	}
 		 */
 		spin_lock(&sb >s_root >d_inode >i_lock);
 		spin_lock(&sb >s_root >d_lock);
 		hlist_del_init(&sb >s_root >d_alias);
 		spin_unlock(&sb >s_root >d_lock);
 		spin_unlock(&sb >s_root >d_inode >i_lock);
 	}
 	spin_lock(&inode >i_lock);
 	/* run all of the dentries associated with this inode.  Since this is a
 	 * directory, there damn well better only be one item on this list */
 	hlist_for_each_entry(alias, &inode >i_dentry, d_alias) {
 		struct dentry *child;
 
 		/* run all of the children of the original inode and fix their
 		 * d_flags to indicate parental interest (their parent is the
 		 * original inode) */
 		spin_lock(&alias >d_lock);
 		list_for_each_entry(child, &alias >d_subdirs, d_u.d_child) {
 			if (!child >d_inode)
 				continue;
 
 	struct dentry *dentry;
 
 	spin_lock(&inode >i_lock);
 	hlist_for_each_entry(dentry, &inode >i_dentry, d_alias) {
 		spin_lock(&dentry >d_lock);
 		if (ocfs2_match_dentry(dentry, parent_blkno, skip_unhashed)) {
 			trace_ocfs2_find_local_alias(dentry >d_name.len,
 	void *d_fsdata;			/* fs specific data */
 
 	struct list_head d_lru;		/* LRU list */
 	/*
 	 * d_child and d_rcu can share memory
 	 */
 	union {
 		struct list_head d_child;	/* child of parent list */
 	 	struct rcu_head d_rcu;
 	} d_u;
 	struct list_head d_subdirs;	/* our children */
 	struct hlist_node d_alias;	/* inode alias list */
 };
 
 /*
 	int ret;
 
 	/* Paranoid: Make sure the parent is the "instances" directory */
 	parent = hlist_entry(inode >i_dentry.first, struct dentry, d_alias);
 	if (WARN_ON_ONCE(parent != trace_instance_dir))
 		return  ENOENT;
 
 	int ret;
 
 	/* Paranoid: Make sure the parent is the "instances" directory */
 	parent = hlist_entry(inode >i_dentry.first, struct dentry, d_alias);
 	if (WARN_ON_ONCE(parent != trace_instance_dir))
 		return  ENOENT;
 
 
 	if (dir) {
 		spin_lock(&dir >d_lock);	/* probably unneeded */
 		list_for_each_entry(child, &dir >d_subdirs, d_u.d_child) {
 			if (child >d_inode)	/* probably unneeded */
 				child >d_inode >i_private = NULL;
 		}
 	spin_lock(&de >d_lock);
 	node = de >d_subdirs.next;
 	while (node != &de >d_subdirs) {
 		struct dentry *d = list_entry(node, struct dentry, d_u.d_child);
 
 		spin_lock_nested(&d >d_lock, DENTRY_D_LOCK_NESTED);
 		list_del_init(node);
 
 	list_for_each(class_node, &class_dir >d_subdirs) {
 		struct dentry *class_subdir = list_entry(class_node,
 					struct dentry, d_u.d_child);
 		struct list_head *class_subdir_node;
 
 		list_for_each(class_subdir_node, &class_subdir >d_subdirs) {
 			struct dentry *d = list_entry(class_subdir_node,
 						struct dentry, d_u.d_child);
 
 			if (d >d_inode)
 				if (d >d_inode >i_mode & S_IFDIR)
After patch : 
 	struct dentry *dentry, *tmp;
 
 	mutex_lock(&dir >d_inode >i_mutex);
 	list_for_each_entry_safe(dentry, tmp, &dir >d_subdirs, d_child) {
 		spin_lock(&dentry >d_lock);
 		if (!(d_unhashed(dentry)) && dentry >d_inode) {
 			dget_dlock(dentry);
 	       inode >i_ino, inode >i_generation, inode);
 
 	ll_lock_dcache(inode);
 	ll_d_hlist_for_each_entry(dentry, p, &inode >i_dentry, d_u.d_alias) {
 		CDEBUG(D_DENTRY, "dentry in drop %.*s (%p) parent %p "
 		       "inode %p flags %d\n", dentry >d_name.len,
 		       dentry >d_name.name, dentry, dentry >d_parent,
 		return;
 
 	list_for_each(tmp, &dentry >d_subdirs) {
 		struct dentry *d = list_entry(tmp, struct dentry, d_child);
 		lustre_dump_dentry(d, recur   1);
 	}
 }
 	struct ll_d_hlist_node *p;
 
 	ll_lock_dcache(dir);
 	ll_d_hlist_for_each_entry(dentry, p, &dir >i_dentry, d_u.d_alias) {
 		spin_lock(&dentry >d_lock);
 		if (!list_empty(&dentry >d_subdirs)) {
 			struct dentry *child;
 
 			list_for_each_entry_safe(child, tmp_subdir,
 						 &dentry >d_subdirs,
 						 d_child) {
 				if (child >d_inode == NULL)
 					d_lustre_invalidate(child, 1);
 			}
 	discon_alias = invalid_alias = NULL;
 
 	ll_lock_dcache(inode);
 	ll_d_hlist_for_each_entry(alias, p, &inode >i_dentry, d_u.d_alias) {
 		LASSERT(alias != dentry);
 
 		spin_lock(&alias >d_lock);
 {
 	struct dentry *parent, *child;
 
 	parent = ll_d_hlist_entry(dir >i_dentry, struct dentry, d_u.d_alias);
 	child = d_lookup(parent, name);
 	if (child) {
 		if (child >d_inode)
 {
 	struct dentry *dentry;
 	spin_lock(&inode >i_lock);
 	hlist_for_each_entry(dentry, &inode >i_dentry, d_u.d_alias) {
 		if (entry_ino == (u32)(long)dentry >d_fsdata) {
 			dentry >d_fsdata = (void *)inode >i_ino;
 			break;
 	spin_lock(&root >d_lock);
 
 	if (prev)
 		next = prev >d_child.next;
 	else {
 		prev = dget_dlock(root);
 		next = prev >d_subdirs.next;
 		return NULL;
 	}
 
 	q = list_entry(next, struct dentry, d_child);
 
 	spin_lock_nested(&q >d_lock, DENTRY_D_LOCK_NESTED);
 	/* Already gone or negative dentry (under construction)   try next */
 	if (!d_count(q) || !simple_positive(q)) {
 		spin_unlock(&q >d_lock);
 		next = q >d_child.next;
 		goto cont;
 	}
 	dget_dlock(q);
 				goto relock;
 			}
 			spin_unlock(&p >d_lock);
 			next = p >d_child.next;
 			p = parent;
 			if (next != &parent >d_subdirs)
 				break;
 		}
 	}
 	ret = list_entry(next, struct dentry, d_child);
 
 	spin_lock_nested(&ret >d_lock, DENTRY_D_LOCK_NESTED);
 	/* Negative dentry   try next */
 	spin_lock(&sbi >lookup_lock);
 	spin_lock(&expired >d_parent >d_lock);
 	spin_lock_nested(&expired >d_lock, DENTRY_D_LOCK_NESTED);
 	list_move(&expired >d_parent >d_subdirs, &expired >d_child);
 	spin_unlock(&expired >d_lock);
 	spin_unlock(&expired >d_parent >d_lock);
 	spin_unlock(&sbi >lookup_lock);
 	/* only consider parents below dentrys in the root */
 	if (IS_ROOT(parent >d_parent))
 		return;
 	d_child = &dentry >d_child;
 	/* Set parent managed if it's becoming empty */
 	if (d_child >next == &parent >d_subdirs &&
 	    d_child >prev == &parent >d_subdirs)
 /*
  * When possible, we try to satisfy a readdir by peeking at the
  * dcache.  We make this work by carefully ordering dentries on
  * d_child when we initially get results back from the MDS, and
  * falling back to a "normal" sync readdir if any dentries in the dir
  * are dropped.
  *
 		p = parent >d_subdirs.prev;
 		dout(" initial p %p/%p\n", p >prev, p >next);
 	} else {
 		p = last >d_child.prev;
 	}
 
 more:
 	dentry = list_entry(p, struct dentry, d_child);
 	di = ceph_dentry(dentry);
 	while (1) {
 		dout(" p %p/%p %s d_subdirs %p/%p\n", p >prev, p >next,
 		     !dentry >d_inode ? " null" : "");
 		spin_unlock(&dentry >d_lock);
 		p = p >prev;
 		dentry = list_entry(p, struct dentry, d_child);
 		di = ceph_dentry(dentry);
 	}
 
 			/* reorder parent's d_subdirs */
 			spin_lock(&parent >d_lock);
 			spin_lock_nested(&dn >d_lock, DENTRY_D_LOCK_NESTED);
 			list_move(&dn >d_child, &parent >d_subdirs);
 			spin_unlock(&dn >d_lock);
 			spin_unlock(&parent >d_lock);
 		}
 	struct dentry *dentry;
 
 	spin_lock(&inode >i_lock);
 	hlist_for_each_entry(dentry, &inode >i_dentry, d_u.d_alias) {
 		if (!d_unhashed(dentry) || IS_ROOT(dentry)) {
 			spin_unlock(&inode >i_lock);
 			return true;
 	struct dentry *de;
 
 	spin_lock(&parent >d_lock);
 	list_for_each_entry(de, &parent >d_subdirs, d_child) {
 		/* don't know what to do with negative dentries */
 		if (de >d_inode ) 
 			coda_flag_inode(de >d_inode, flag);
 /*
  * Usage:
  * dcache >d_inode >i_lock protects:
  *     i_dentry, d_u.d_alias, d_inode of aliases
  * dcache_hash_bucket lock protects:
  *     the dcache hash table
  * s_anon bl list spinlock protects:
  *     d_unhashed()
  *     d_parent and d_subdirs
  *     childrens' d_child and d_parent
  *     d_u.d_alias, d_inode
  *
  * Ordering:
  * dentry >d_inode >i_lock
 {
 	struct dentry *dentry = container_of(head, struct dentry, d_u.d_rcu);
 
 	kmem_cache_free(dentry_cache, dentry); 
 }
 
 static void __d_free_external(struct rcu_head *head)
 {
 	struct dentry *dentry = container_of(head, struct dentry, d_u.d_rcu);
 	kfree(external_name(dentry));
 	kmem_cache_free(dentry_cache, dentry); 
 }
 
 static void dentry_free(struct dentry *dentry)
 {
 	WARN_ON(!hlist_unhashed(&dentry >d_u.d_alias));
 	if (unlikely(dname_external(dentry))) {
 		struct external_name *p = external_name(dentry);
 		if (likely(atomic_dec_and_test(&p >u.count))) {
 	struct inode *inode = dentry >d_inode;
 	if (inode) {
 		dentry >d_inode = NULL;
 		hlist_del_init(&dentry >d_u.d_alias);
 		spin_unlock(&dentry >d_lock);
 		spin_unlock(&inode >i_lock);
 		if (!inode >i_nlink)
 	struct inode *inode = dentry >d_inode;
 	__d_clear_type(dentry);
 	dentry >d_inode = NULL;
 	hlist_del_init(&dentry >d_u.d_alias);
 	dentry_rcuwalk_barrier(dentry);
 	spin_unlock(&dentry >d_lock);
 	spin_unlock(&inode >i_lock);
 	}
 	/* if it was on the hash then remove it */
 	__d_drop(dentry);
 	list_del(&dentry >d_child);
 	/*
 	 * Inform d_walk() that we are no longer attached to the
 	 * dentry tree
 
 again:
 	discon_alias = NULL;
 	hlist_for_each_entry(alias, &inode >i_dentry, d_u.d_alias) {
 		spin_lock(&alias >d_lock);
  		if (S_ISDIR(inode >i_mode) || !d_unhashed(alias)) {
 			if (IS_ROOT(alias) &&
 	struct dentry *dentry;
 restart:
 	spin_lock(&inode >i_lock);
 	hlist_for_each_entry(dentry, &inode >i_dentry, d_u.d_alias) {
 		spin_lock(&dentry >d_lock);
 		if (!dentry >d_lockref.count) {
 			struct dentry *parent = lock_parent(dentry);
 resume:
 	while (next != &this_parent >d_subdirs) {
 		struct list_head *tmp = next;
 		struct dentry *dentry = list_entry(tmp, struct dentry, d_child);
 		next = tmp >next;
 
 		spin_lock_nested(&dentry >d_lock, DENTRY_D_LOCK_NESTED);
 			goto rename_retry;
 		}
 		rcu_read_unlock();
 		next = child >d_child.next;
 		goto resume;
 	}
 	if (need_seqretry(&rename_lock, seq)) {
 	INIT_HLIST_BL_NODE(&dentry >d_hash);
 	INIT_LIST_HEAD(&dentry >d_lru);
 	INIT_LIST_HEAD(&dentry >d_subdirs);
 	INIT_HLIST_NODE(&dentry >d_u.d_alias);
 	INIT_LIST_HEAD(&dentry >d_child);
 	d_set_d_op(dentry, dentry >d_sb >s_d_op);
 
 	this_cpu_inc(nr_dentry);
 	 */
 	__dget_dlock(parent);
 	dentry >d_parent = parent;
 	list_add(&dentry >d_child, &parent >d_subdirs);
 	spin_unlock(&parent >d_lock);
 
 	return dentry;
 	spin_lock(&dentry >d_lock);
 	__d_set_type(dentry, add_flags);
 	if (inode)
 		hlist_add_head(&dentry >d_u.d_alias, &inode >i_dentry);
 	dentry >d_inode = inode;
 	dentry_rcuwalk_barrier(dentry);
 	spin_unlock(&dentry >d_lock);
 
 void d_instantiate(struct dentry *entry, struct inode * inode)
 {
 	BUG_ON(!hlist_unhashed(&entry >d_u.d_alias));
 	if (inode)
 		spin_lock(&inode >i_lock);
 	__d_instantiate(entry, inode);
 		return NULL;
 	}
 
 	hlist_for_each_entry(alias, &inode >i_dentry, d_u.d_alias) {
 		/*
 		 * Don't need alias >d_lock here, because aliases with
 		 * d_parent == entry >d_parent are not subject to name or
 {
 	struct dentry *result;
 
 	BUG_ON(!hlist_unhashed(&entry >d_u.d_alias));
 
 	if (inode)
 		spin_lock(&inode >i_lock);
  */
 int d_instantiate_no_diralias(struct dentry *entry, struct inode *inode)
 {
 	BUG_ON(!hlist_unhashed(&entry >d_u.d_alias));
 
 	spin_lock(&inode >i_lock);
 	if (S_ISDIR(inode >i_mode) && !hlist_empty(&inode >i_dentry)) {
 
 	if (hlist_empty(&inode >i_dentry))
 		return NULL;
 	alias = hlist_entry(inode >i_dentry.first, struct dentry, d_u.d_alias);
 	__dget(alias);
 	return alias;
 }
 	spin_lock(&tmp >d_lock);
 	tmp >d_inode = inode;
 	tmp >d_flags |= add_flags;
 	hlist_add_head(&tmp >d_u.d_alias, &inode >i_dentry);
 	hlist_bl_lock(&tmp >d_sb >s_anon);
 	hlist_bl_add_head(&tmp >d_hash, &tmp >d_sb >s_anon);
 	hlist_bl_unlock(&tmp >d_sb >s_anon);
 	struct dentry *child;
 
 	spin_lock(&dparent >d_lock);
 	list_for_each_entry(child, &dparent >d_subdirs, d_child) {
 		if (dentry == child) {
 			spin_lock_nested(&dentry >d_lock, DENTRY_D_LOCK_NESTED);
 			__dget_dlock(dentry);
 		/* splicing a tree */
 		dentry >d_parent = target >d_parent;
 		target >d_parent = target;
 		list_del_init(&target >d_child);
 		list_move(&dentry >d_child, &dentry >d_parent >d_subdirs);
 	} else {
 		/* swapping two dentries */
 		swap(dentry >d_parent, target >d_parent);
 		list_move(&target >d_child, &target >d_parent >d_subdirs);
 		list_move(&dentry >d_child, &dentry >d_parent >d_subdirs);
 		if (exchange)
 			fsnotify_d_move(target);
 		fsnotify_d_move(dentry);
 {
 	inode_dec_link_count(inode);
 	BUG_ON(dentry >d_name.name != dentry >d_iname ||
 		!hlist_unhashed(&dentry >d_u.d_alias) ||
 		!d_unlinked(dentry));
 	spin_lock(&dentry >d_parent >d_lock);
 	spin_lock_nested(&dentry >d_lock, DENTRY_D_LOCK_NESTED);
 	 * use the d_u.d_child as the rcu head and corrupt this list.
 	 */
 	spin_lock(&parent >d_lock);
 	list_for_each_entry(child, &parent >d_subdirs, d_child) {
 		if (!debugfs_positive(child))
 			continue;
 
 
 	inode = result >d_inode;
 	spin_lock(&inode >i_lock);
 	hlist_for_each_entry(dentry, &inode >i_dentry, d_u.d_alias) {
 		dget(dentry);
 		spin_unlock(&inode >i_lock);
 		if (toput)
 
 			spin_lock(&dentry >d_lock);
 			/* d_lock not required for cursor */
 			list_del(&cursor >d_child);
 			p = dentry >d_subdirs.next;
 			while (n && p != &dentry >d_subdirs) {
 				struct dentry *next;
 				next = list_entry(p, struct dentry, d_child);
 				spin_lock_nested(&next >d_lock, DENTRY_D_LOCK_NESTED);
 				if (simple_positive(next))
 					n  ;
 				spin_unlock(&next >d_lock);
 				p = p >next;
 			}
 			list_add_tail(&cursor >d_child, p);
 			spin_unlock(&dentry >d_lock);
 		}
 	}
 {
 	struct dentry *dentry = file >f_path.dentry;
 	struct dentry *cursor = file >private_data;
 	struct list_head *p, *q = &cursor >d_child;
 
 	if (!dir_emit_dots(file, ctx))
 		return 0;
 		list_move(q, &dentry >d_subdirs);
 
 	for (p = q >next; p != &dentry >d_subdirs; p = p >next) {
 		struct dentry *next = list_entry(p, struct dentry, d_child);
 		spin_lock_nested(&next >d_lock, DENTRY_D_LOCK_NESTED);
 		if (!simple_positive(next)) {
 			spin_unlock(&next >d_lock);
 	int ret = 0;
 
 	spin_lock(&dentry >d_lock);
 	list_for_each_entry(child, &dentry >d_subdirs, d_child) {
 		spin_lock_nested(&child >d_lock, DENTRY_D_LOCK_NESTED);
 		if (simple_positive(child)) {
 			spin_unlock(&child >d_lock);
 
 	/* If a pointer is invalid, we search the dentry. */
 	spin_lock(&parent >d_lock);
 	list_for_each_entry(dent, &parent >d_subdirs, d_child) {
 		if ((unsigned long)dent >d_fsdata == fpos) {
 			if (dent >d_inode)
 				dget(dent);
 	struct dentry *dentry;
 
 	spin_lock(&parent >d_lock);
 	list_for_each_entry(dentry, &parent >d_subdirs, d_child) {
 		if (dentry >d_fsdata == NULL)
 			ncp_age_dentry(server, dentry);
 		else
 	struct dentry *dentry;
 
 	spin_lock(&parent >d_lock);
 	list_for_each_entry(dentry, &parent >d_subdirs, d_child) {
 		dentry >d_fsdata = NULL;
 		ncp_age_dentry(server, dentry);
 	}
 		 */
 		spin_lock(&sb >s_root >d_inode >i_lock);
 		spin_lock(&sb >s_root >d_lock);
 		hlist_del_init(&sb >s_root >d_u.d_alias);
 		spin_unlock(&sb >s_root >d_lock);
 		spin_unlock(&sb >s_root >d_inode >i_lock);
 	}
 	spin_lock(&inode >i_lock);
 	/* run all of the dentries associated with this inode.  Since this is a
 	 * directory, there damn well better only be one item on this list */
 	hlist_for_each_entry(alias, &inode >i_dentry, d_u.d_alias) {
 		struct dentry *child;
 
 		/* run all of the children of the original inode and fix their
 		 * d_flags to indicate parental interest (their parent is the
 		 * original inode) */
 		spin_lock(&alias >d_lock);
 		list_for_each_entry(child, &alias >d_subdirs, d_child) {
 			if (!child >d_inode)
 				continue;
 
 	struct dentry *dentry;
 
 	spin_lock(&inode >i_lock);
 	hlist_for_each_entry(dentry, &inode >i_dentry, d_u.d_alias) {
 		spin_lock(&dentry >d_lock);
 		if (ocfs2_match_dentry(dentry, parent_blkno, skip_unhashed)) {
 			trace_ocfs2_find_local_alias(dentry >d_name.len,
 	void *d_fsdata;			/* fs specific data */
 
 	struct list_head d_lru;		/* LRU list */
 	struct list_head d_child;	/* child of parent list */
 	struct list_head d_subdirs;	/* our children */
 	/*
 	 * d_alias and d_rcu can share memory
 	 */
 	union {
 		struct hlist_node d_alias;	/* inode alias list */
 	 	struct rcu_head d_rcu;
 	} d_u;
 };
 
 /*
 	int ret;
 
 	/* Paranoid: Make sure the parent is the "instances" directory */
 	parent = hlist_entry(inode >i_dentry.first, struct dentry, d_u.d_alias);
 	if (WARN_ON_ONCE(parent != trace_instance_dir))
 		return  ENOENT;
 
 	int ret;
 
 	/* Paranoid: Make sure the parent is the "instances" directory */
 	parent = hlist_entry(inode >i_dentry.first, struct dentry, d_u.d_alias);
 	if (WARN_ON_ONCE(parent != trace_instance_dir))
 		return  ENOENT;
 
 
 	if (dir) {
 		spin_lock(&dir >d_lock);	/* probably unneeded */
 		list_for_each_entry(child, &dir >d_subdirs, d_child) {
 			if (child >d_inode)	/* probably unneeded */
 				child >d_inode >i_private = NULL;
 		}
 	spin_lock(&de >d_lock);
 	node = de >d_subdirs.next;
 	while (node != &de >d_subdirs) {
 		struct dentry *d = list_entry(node, struct dentry, d_child);
 
 		spin_lock_nested(&d >d_lock, DENTRY_D_LOCK_NESTED);
 		list_del_init(node);
 
 	list_for_each(class_node, &class_dir >d_subdirs) {
 		struct dentry *class_subdir = list_entry(class_node,
 					struct dentry, d_child);
 		struct list_head *class_subdir_node;
 
 		list_for_each(class_subdir_node, &class_subdir >d_subdirs) {
 			struct dentry *d = list_entry(class_subdir_node,
 						struct dentry, d_child);
 
 			if (d >d_inode)
 				if (d >d_inode >i_mode & S_IFDIR)
