CVE Number : CVE-2019-11477
Commit Message : 
tcp: limit payload size of sacked skbs
Commit Details : 
Jonathan Looney reported that TCP can trigger the following crash
in tcp_shifted_skb() :

	BUG_ON(tcp_skb_pcount(skb) < pcount);

This can happen if the remote peer has advertized the smallest
MSS that linux TCP accepts : 48

An skb can hold 17 fragments, and each fragment can hold 32KB
on x86, or 64KB on PowerPC.

This means that the 16bit witdh of TCP_SKB_CB(skb)->tcp_gso_segs
can overflow.

Note that tcp_sendmsg() builds skbs with less than 64KB
of payload, so this problem needs SACK to be enabled.
SACK blocks allow TCP to coalesce multiple skbs in the retransmit
queue, thus filling the 17 fragments to maximal capacity.

CVE-2019-11477 -- u16 overflow of TCP_SKB_CB(skb)->tcp_gso_segs

Fixes: 832d11c5cd07 ("tcp: Try to restore large SKBs while SACK processing")
Signed-off-by: Eric Dumazet <edumazet@google.com>
Reported-by: Jonathan Looney <jtl@netflix.com>
Acked-by: Neal Cardwell <ncardwell@google.com>
Reviewed-by: Tyler Hicks <tyhicks@canonical.com>
Cc: Yuchung Cheng <ycheng@google.com>
Cc: Bruce Curtis <brucec@netflix.com>
Cc: Jonathan Lemon <jonathan.lemon@gmail.com>
Signed-off-by: David S. Miller <davem@davemloft.net>

Before patch : 
 
 	return (user_mss && user_mss < mss) ? user_mss : mss;
 }
 #endif	/* _LINUX_TCP_H */
 
 #define MAX_TCP_HEADER	(128   MAX_HEADER)
 #define MAX_TCP_OPTION_SPACE 40
 
 /*
  * Never offer a window over 32767 without using window scaling. Some
 	unsigned long limit;
 	unsigned int i;
 
 	BUILD_BUG_ON(sizeof(struct tcp_skb_cb) >
 		     FIELD_SIZEOF(struct sk_buff, cb));
 
 	TCP_SKB_CB(skb) >seq  = shifted;
 
 	tcp_skb_pcount_add(prev, pcount);
 	BUG_ON(tcp_skb_pcount(skb) < pcount);
 	tcp_skb_pcount_add(skb,  pcount);
 
 	/* When we're adding to gso_segs == 1, gso_size will be zero,
 	return !skb_headlen(skb) && skb_is_nonlinear(skb);
 }
 
 /* Try collapsing SACK blocks spanning across multiple skbs to a single
  * skb.
  */
 	if (!after(TCP_SKB_CB(skb) >seq   len, tp >snd_una))
 		goto fallback;
 
 	if (!skb_shift(prev, skb, len))
 		goto fallback;
 	if (!tcp_shifted_skb(sk, prev, skb, state, pcount, len, mss, dup_sack))
 		goto out;
 		goto out;
 
 	len = skb >len;
 	if (skb_shift(prev, skb, len)) {
 		pcount  = tcp_skb_pcount(skb);
 		tcp_shifted_skb(sk, prev, skb, state, tcp_skb_pcount(skb),
 				len, mss, 0);
 	}
 
 out:
 	return prev;
 	mss_now  = icsk >icsk_ext_hdr_len;
 
 	/* Then reserve room for full set of TCP options and 8 bytes of data */
 	if (mss_now < 48)
 		mss_now = 48;
 	return mss_now;
 }
 
 		if (next_skb_size <= skb_availroom(skb))
 			skb_copy_bits(next_skb, 0, skb_put(skb, next_skb_size),
 				      next_skb_size);
 		else if (!skb_shift(skb, next_skb, next_skb_size))
 			return false;
 	}
 	tcp_highest_sack_replace(sk, next_skb, skb);
After patch : 
 
 	return (user_mss && user_mss < mss) ? user_mss : mss;
 }
 
 int tcp_skb_shift(struct sk_buff *to, struct sk_buff *from, int pcount,
 		  int shiftlen);
 
 #endif	/* _LINUX_TCP_H */
 
 #define MAX_TCP_HEADER	(128   MAX_HEADER)
 #define MAX_TCP_OPTION_SPACE 40
 #define TCP_MIN_SND_MSS		48
 #define TCP_MIN_GSO_SIZE	(TCP_MIN_SND_MSS   MAX_TCP_OPTION_SPACE)
 
 /*
  * Never offer a window over 32767 without using window scaling. Some
 	unsigned long limit;
 	unsigned int i;
 
 	BUILD_BUG_ON(TCP_MIN_SND_MSS <= MAX_TCP_OPTION_SPACE);
 	BUILD_BUG_ON(sizeof(struct tcp_skb_cb) >
 		     FIELD_SIZEOF(struct sk_buff, cb));
 
 	TCP_SKB_CB(skb) >seq  = shifted;
 
 	tcp_skb_pcount_add(prev, pcount);
 	WARN_ON_ONCE(tcp_skb_pcount(skb) < pcount);
 	tcp_skb_pcount_add(skb,  pcount);
 
 	/* When we're adding to gso_segs == 1, gso_size will be zero,
 	return !skb_headlen(skb) && skb_is_nonlinear(skb);
 }
 
 int tcp_skb_shift(struct sk_buff *to, struct sk_buff *from,
 		  int pcount, int shiftlen)
 {
 	/* TCP min gso_size is 8 bytes (TCP_MIN_GSO_SIZE)
 	 * Since TCP_SKB_CB(skb) >tcp_gso_segs is 16 bits, we need
 	 * to make sure not storing more than 65535 * 8 bytes per skb,
 	 * even if current MSS is bigger.
 	 */
 	if (unlikely(to >len   shiftlen >= 65535 * TCP_MIN_GSO_SIZE))
 		return 0;
 	if (unlikely(tcp_skb_pcount(to)   pcount > 65535))
 		return 0;
 	return skb_shift(to, from, shiftlen);
 }
 
 /* Try collapsing SACK blocks spanning across multiple skbs to a single
  * skb.
  */
 	if (!after(TCP_SKB_CB(skb) >seq   len, tp >snd_una))
 		goto fallback;
 
 	if (!tcp_skb_shift(prev, skb, pcount, len))
 		goto fallback;
 	if (!tcp_shifted_skb(sk, prev, skb, state, pcount, len, mss, dup_sack))
 		goto out;
 		goto out;
 
 	len = skb >len;
 	pcount = tcp_skb_pcount(skb);
 	if (tcp_skb_shift(prev, skb, pcount, len))
 		tcp_shifted_skb(sk, prev, skb, state, pcount,
 				len, mss, 0);
 
 out:
 	return prev;
 	mss_now  = icsk >icsk_ext_hdr_len;
 
 	/* Then reserve room for full set of TCP options and 8 bytes of data */
 	if (mss_now < TCP_MIN_SND_MSS)
 		mss_now = TCP_MIN_SND_MSS;
 	return mss_now;
 }
 
 		if (next_skb_size <= skb_availroom(skb))
 			skb_copy_bits(next_skb, 0, skb_put(skb, next_skb_size),
 				      next_skb_size);
 		else if (!tcp_skb_shift(skb, next_skb, 1, next_skb_size))
 			return false;
 	}
 	tcp_highest_sack_replace(sk, next_skb, skb);
