CVE Number : CVE-2012-3552
Commit Message : 
inet: add RCU protection to inet->opt
Commit Details : 
We lack proper synchronization to manipulate inet->opt ip_options

Problem is ip_make_skb() calls ip_setup_cork() and
ip_setup_cork() possibly makes a copy of ipc->opt (struct ip_options),
without any protection against another thread manipulating inet->opt.

Another thread can change inet->opt pointer and free old one under us.

Use RCU to protect inet->opt (changed to inet->inet_opt).

Instead of handling atomic refcounts, just copy ip_options when
necessary, to avoid cache line dirtying.

We cant insert an rcu_head in struct ip_options since its included in
skb->cb, so this patch is large because I had to introduce a new
ip_options_rcu structure.

Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
Cc: Herbert Xu <herbert@gondor.apana.org.au>
Signed-off-by: David S. Miller <davem@davemloft.net>

Before patch : 
 	unsigned char	__data[0];
 };
 
 #define optlength(opt) (sizeof(struct ip_options)   opt >optlen)
 
 struct inet_request_sock {
 	struct request_sock	req;
 				acked	   : 1,
 				no_srccheck: 1;
 	kmemcheck_bitfield_end(flags);
 	struct ip_options	*opt;
 };
 
 static inline struct inet_request_sock *inet_rsk(const struct request_sock *sk)
 	__be16			inet_sport;
 	__u16			inet_id;
 
 	struct ip_options	*opt;
 	__u8			tos;
 	__u8			min_ttl;
 	__u8			mc_ttl;
 struct ipcm_cookie {
 	__be32			addr;
 	int			oif;
 	struct ip_options	*opt;
 	__u8			tx_flags;
 };
 
 
 extern int		ip_build_and_send_pkt(struct sk_buff *skb, struct sock *sk,
 					      __be32 saddr, __be32 daddr,
 					      struct ip_options *opt);
 extern int		ip_rcv(struct sk_buff *skb, struct net_device *dev,
 			       struct packet_type *pt, struct net_device *orig_dev);
 extern int		ip_local_deliver(struct sk_buff *skb);
  *	Functions provided by ip_options.c
  */
 
 extern void ip_options_build(struct sk_buff *skb, struct ip_options *opt, __be32 daddr, struct rtable *rt, int is_frag);
 extern int ip_options_echo(struct ip_options *dopt, struct sk_buff *skb);
 extern void ip_options_fragment(struct sk_buff *skb);
 extern int ip_options_compile(struct net *net,
 			      struct ip_options *opt, struct sk_buff *skb);
 extern int ip_options_get(struct net *net, struct ip_options **optp,
 			  unsigned char *data, int optlen);
 extern int ip_options_get_from_user(struct net *net, struct ip_options **optp,
 				    unsigned char __user *data, int optlen);
 extern void ip_options_undo(struct ip_options * opt);
 extern void ip_forward_options(struct sk_buff *skb);
 	struct flowi4 fl4;
 	struct rtable *rt;
 	int err;
 
 	dp >dccps_role = DCCP_ROLE_CLIENT;
 
 		return  EAFNOSUPPORT;
 
 	nexthop = daddr = usin >sin_addr.s_addr;
 	if (inet >opt != NULL && inet >opt >srr) {
 		if (daddr == 0)
 			return  EINVAL;
 		nexthop = inet >opt >faddr;
 	}
 
 	orig_sport = inet >inet_sport;
 		return  ENETUNREACH;
 	}
 
 	if (inet >opt == NULL || !inet >opt >srr)
 		daddr = rt >rt_dst;
 
 	if (inet >inet_saddr == 0)
 	inet >inet_daddr = daddr;
 
 	inet_csk(sk) >icsk_ext_hdr_len = 0;
 	if (inet >opt != NULL)
 		inet_csk(sk) >icsk_ext_hdr_len = inet >opt >optlen;
 	/*
 	 * Socket identity is still unknown (sport may be zero).
 	 * However we set state to DCCP_REQUESTING and not releasing socket
 	newinet >inet_daddr	= ireq >rmt_addr;
 	newinet >inet_rcv_saddr = ireq >loc_addr;
 	newinet >inet_saddr	= ireq >loc_addr;
 	newinet >opt	   = ireq >opt;
 	ireq >opt	   = NULL;
 	newinet >mc_index  = inet_iif(skb);
 	newinet >mc_ttl	   = ip_hdr(skb) >ttl;
 
 	   First: no IPv4 options.
 	 */
 	newinet >opt = NULL;
 
 	/* Clone RX bits */
 	newnp >rxopt.all = np >rxopt.all;
 	WARN_ON(sk >sk_wmem_queued);
 	WARN_ON(sk >sk_forward_alloc);
 
 	kfree(inet >opt);
 	dst_release(rcu_dereference_check(sk >sk_dst_cache, 1));
 	sk_refcnt_debug_dec(sk);
 }
 	struct flowi4 fl4;
 	struct rtable *rt;
 	__be32 new_saddr;
 
 	if (inet >opt && inet >opt >srr)
 		daddr = inet >opt >faddr;
 
 	/* Query new route. */
 	rt = ip_route_connect(&fl4, daddr, 0, RT_CONN_FLAGS(sk),
 	struct inet_sock *inet = inet_sk(sk);
 	struct rtable *rt = (struct rtable *)__sk_dst_check(sk, 0);
 	__be32 daddr;
 	int err;
 
 	/* Route is OK, nothing to do. */
 		return 0;
 
 	/* Reroute. */
 	daddr = inet >inet_daddr;
 	if (inet >opt && inet >opt >srr)
 		daddr = inet >opt >faddr;
 	rt = ip_route_output_ports(sock_net(sk), sk, daddr, inet >inet_saddr,
 				   inet >inet_dport, inet >inet_sport,
 				   sk >sk_protocol, RT_CONN_FLAGS(sk),
 	return CIPSO_V4_HDR_LEN   ret_val;
 }
 
 /**
  * cipso_v4_sock_setattr   Add a CIPSO option to a socket
  * @sk: the socket
 	unsigned char *buf = NULL;
 	u32 buf_len;
 	u32 opt_len;
 	struct ip_options *opt = NULL;
 	struct inet_sock *sk_inet;
 	struct inet_connection_sock *sk_conn;
 
 		ret_val =  ENOMEM;
 		goto socket_setattr_failure;
 	}
 	memcpy(opt >__data, buf, buf_len);
 	opt >optlen = opt_len;
 	opt >cipso = sizeof(struct iphdr);
 	kfree(buf);
 	buf = NULL;
 
 	sk_inet = inet_sk(sk);
 	if (sk_inet >is_icsk) {
 		sk_conn = inet_csk(sk);
 		if (sk_inet >opt)
 			sk_conn >icsk_ext_hdr_len  = sk_inet >opt >optlen;
 		sk_conn >icsk_ext_hdr_len  = opt >optlen;
 		sk_conn >icsk_sync_mss(sk, sk_conn >icsk_pmtu_cookie);
 	}
 	opt = xchg(&sk_inet >opt, opt);
 	kfree(opt);
 
 	return 0;
 
 	unsigned char *buf = NULL;
 	u32 buf_len;
 	u32 opt_len;
 	struct ip_options *opt = NULL;
 	struct inet_request_sock *req_inet;
 
 	/* We allocate the maximum CIPSO option size here so we are probably
 		ret_val =  ENOMEM;
 		goto req_setattr_failure;
 	}
 	memcpy(opt >__data, buf, buf_len);
 	opt >optlen = opt_len;
 	opt >cipso = sizeof(struct iphdr);
 	kfree(buf);
 	buf = NULL;
 
 	req_inet = inet_rsk(req);
 	opt = xchg(&req_inet >opt, opt);
 	kfree(opt);
 
 	return 0;
 
  * values on failure.
  *
  */
 static int cipso_v4_delopt(struct ip_options **opt_ptr)
 {
 	int hdr_delta = 0;
 	struct ip_options *opt = *opt_ptr;
 
 	if (opt >srr || opt >rr || opt >ts || opt >router_alert) {
 		u8 cipso_len;
 		u8 cipso_off;
 		unsigned char *cipso_ptr;
 		int iter;
 		int optlen_new;
 
 		cipso_off = opt >cipso   sizeof(struct iphdr);
 		cipso_ptr = &opt >__data[cipso_off];
 		cipso_len = cipso_ptr[1];
 
 		if (opt >srr > opt >cipso)
 			opt >srr  = cipso_len;
 		if (opt >rr > opt >cipso)
 			opt >rr  = cipso_len;
 		if (opt >ts > opt >cipso)
 			opt >ts  = cipso_len;
 		if (opt >router_alert > opt >cipso)
 			opt >router_alert  = cipso_len;
 		opt >cipso = 0;
 
 		memmove(cipso_ptr, cipso_ptr   cipso_len,
 			opt >optlen   cipso_off   cipso_len);
 
 		/* determining the new total option length is tricky because of
 		 * the padding necessary, the only thing i can think to do at
 		 * from there we can determine the new total option length */
 		iter = 0;
 		optlen_new = 0;
 		while (iter < opt >optlen)
 			if (opt >__data[iter] != IPOPT_NOP) {
 				iter  = opt >__data[iter   1];
 				optlen_new = iter;
 			} else
 				iter  ;
 		hdr_delta = opt >optlen;
 		opt >optlen = (optlen_new   3) & ~3;
 		hdr_delta  = opt >optlen;
 	} else {
 		/* only the cipso option was present on the socket so we can
 		 * remove the entire option struct */
 		*opt_ptr = NULL;
 		hdr_delta = opt >optlen;
 		kfree(opt);
 	}
 
 	return hdr_delta;
 void cipso_v4_sock_delattr(struct sock *sk)
 {
 	int hdr_delta;
 	struct ip_options *opt;
 	struct inet_sock *sk_inet;
 
 	sk_inet = inet_sk(sk);
 	opt = sk_inet >opt;
 	if (opt == NULL || opt >cipso == 0)
 		return;
 
 	hdr_delta = cipso_v4_delopt(&sk_inet >opt);
 	if (sk_inet >is_icsk && hdr_delta > 0) {
 		struct inet_connection_sock *sk_conn = inet_csk(sk);
 		sk_conn >icsk_ext_hdr_len  = hdr_delta;
  */
 void cipso_v4_req_delattr(struct request_sock *req)
 {
 	struct ip_options *opt;
 	struct inet_request_sock *req_inet;
 
 	req_inet = inet_rsk(req);
 	opt = req_inet >opt;
 	if (opt == NULL || opt >cipso == 0)
 		return;
 
 	cipso_v4_delopt(&req_inet >opt);
  */
 int cipso_v4_sock_getattr(struct sock *sk, struct netlbl_lsm_secattr *secattr)
 {
 	struct ip_options *opt;
 
 	opt = inet_sk(sk) >opt;
 	if (opt == NULL || opt >cipso == 0)
 		return  ENOMSG;
 
 	return cipso_v4_getattr(opt >__data   opt >cipso   sizeof(struct iphdr),
 				secattr);
 }
 
 /**
 		__be32	       times[3];
 	} data;
 	int head_len;
 	struct ip_options replyopts;
 	unsigned char  optbuf[40];
 };
 
 /* An array of errno for error messages from dest unreach. */
 	struct inet_sock *inet;
 	__be32 daddr;
 
 	if (ip_options_echo(&icmp_param >replyopts, skb))
 		return;
 
 	sk = icmp_xmit_lock(net);
 	daddr = ipc.addr = rt >rt_src;
 	ipc.opt = NULL;
 	ipc.tx_flags = 0;
 	if (icmp_param >replyopts.optlen) {
 		ipc.opt = &icmp_param >replyopts;
 		if (ipc.opt >srr)
 			daddr = icmp_param >replyopts.faddr;
 	}
 	{
 		struct flowi4 fl4 = {
 					struct icmp_bxm *param)
 {
 	struct flowi4 fl4 = {
 		.daddr = (param >replyopts.srr ?
 			  param >replyopts.faddr : iph >saddr),
 		.saddr = saddr,
 		.flowi4_tos = RT_TOS(tos),
 		.flowi4_proto = IPPROTO_ICMP,
 					   IPTOS_PREC_INTERNETCONTROL) :
 					  iph >tos;
 
 	if (ip_options_echo(&icmp_param.replyopts, skb_in))
 		goto out_unlock;
 
 
 	icmp_param.offset = skb_network_offset(skb_in);
 	inet_sk(sk) >tos = tos;
 	ipc.addr = iph >saddr;
 	ipc.opt = &icmp_param.replyopts;
 	ipc.tx_flags = 0;
 
 	rt = icmp_route_lookup(net, skb_in, iph, saddr, tos,
 	room = dst_mtu(&rt >dst);
 	if (room > 576)
 		room = 576;
 	room  = sizeof(struct iphdr)   icmp_param.replyopts.optlen;
 	room  = sizeof(struct icmphdr);
 
 	icmp_param.data_len = skb_in >len   icmp_param.offset;
 {
 	struct rtable *rt;
 	const struct inet_request_sock *ireq = inet_rsk(req);
 	struct ip_options *opt = inet_rsk(req) >opt;
 	struct net *net = sock_net(sk);
 	struct flowi4 fl4;
 
 	flowi4_init_output(&fl4, sk >sk_bound_dev_if, sk >sk_mark,
 			   RT_CONN_FLAGS(sk), RT_SCOPE_UNIVERSE,
 			   sk >sk_protocol, inet_sk_flowi_flags(sk),
 			   (opt && opt >srr) ? opt >faddr : ireq >rmt_addr,
 			   ireq >loc_addr, ireq >rmt_port, inet_sk(sk) >inet_sport);
 	security_req_classify_flow(req, flowi4_to_flowi(&fl4));
 	rt = ip_route_output_flow(net, &fl4, sk);
 	if (IS_ERR(rt))
 		goto no_route;
 	if (opt && opt >is_strictroute && rt >rt_dst != rt >rt_gateway)
 		goto route_err;
 	return &rt >dst;
 
  * saddr is address of outgoing interface.
  */
 
 void ip_options_build(struct sk_buff * skb, struct ip_options * opt,
 			    __be32 daddr, struct rtable *rt, int is_frag)
 {
 	unsigned char *iph = skb_network_header(skb);
  * NOTE: dopt cannot point to skb.
  */
 
 int ip_options_echo(struct ip_options * dopt, struct sk_buff * skb)
 {
 	struct ip_options *sopt;
 	unsigned char *sptr, *dptr;
 	int soffset, doffset;
 	int	optlen;
 
 	sopt = &(IPCB(skb) >opt);
 
 	if (sopt >optlen == 0) {
 		dopt >optlen = 0;
 		return 0;
 	}
 
 	sptr = skb_network_header(skb);
 	dptr = dopt >__data;
 		dopt >optlen  = optlen;
 	}
 	if (sopt >srr) {
 		unsigned char * start = sptr sopt >srr;
 		__be32 faddr;
 
 		optlen  = start[1];
 	}
 }
 
 static struct ip_options *ip_options_get_alloc(const int optlen)
 {
 	return kzalloc(sizeof(struct ip_options)   ((optlen   3) & ~3),
 		       GFP_KERNEL);
 }
 
 static int ip_options_get_finish(struct net *net, struct ip_options **optp,
 				 struct ip_options *opt, int optlen)
 {
 	while (optlen & 3)
 		opt >__data[optlen  ] = IPOPT_END;
 	opt >optlen = optlen;
 	if (optlen && ip_options_compile(net, opt, NULL)) {
 		kfree(opt);
 		return  EINVAL;
 	}
 	return 0;
 }
 
 int ip_options_get_from_user(struct net *net, struct ip_options **optp,
 			     unsigned char __user *data, int optlen)
 {
 	struct ip_options *opt = ip_options_get_alloc(optlen);
 
 	if (!opt)
 		return  ENOMEM;
 	if (optlen && copy_from_user(opt >__data, data, optlen)) {
 		kfree(opt);
 		return  EFAULT;
 	}
 	return ip_options_get_finish(net, optp, opt, optlen);
 }
 
 int ip_options_get(struct net *net, struct ip_options **optp,
 		   unsigned char *data, int optlen)
 {
 	struct ip_options *opt = ip_options_get_alloc(optlen);
 
 	if (!opt)
 		return  ENOMEM;
 	if (optlen)
 		memcpy(opt >__data, data, optlen);
 	return ip_options_get_finish(net, optp, opt, optlen);
 }
 
  *
  */
 int ip_build_and_send_pkt(struct sk_buff *skb, struct sock *sk,
 			  __be32 saddr, __be32 daddr, struct ip_options *opt)
 {
 	struct inet_sock *inet = inet_sk(sk);
 	struct rtable *rt = skb_rtable(skb);
 	struct iphdr *iph;
 
 	/* Build the IP header. */
 	skb_push(skb, sizeof(struct iphdr)   (opt ? opt >optlen : 0));
 	skb_reset_network_header(skb);
 	iph = ip_hdr(skb);
 	iph >version  = 4;
 	iph >protocol = sk >sk_protocol;
 	ip_select_ident(iph, &rt >dst, sk);
 
 	if (opt && opt >optlen) {
 		iph >ihl  = opt >optlen>>2;
 		ip_options_build(skb, opt, daddr, rt, 0);
 	}
 
 	skb >priority = sk >sk_priority;
 {
 	struct sock *sk = skb >sk;
 	struct inet_sock *inet = inet_sk(sk);
 	struct ip_options *opt = inet >opt;
 	struct rtable *rt;
 	struct iphdr *iph;
 	int res;
 	 * f.e. by something like SCTP.
 	 */
 	rcu_read_lock();
 	rt = skb_rtable(skb);
 	if (rt != NULL)
 		goto packet_routed;
 
 		/* Use correct destination address if we have options. */
 		daddr = inet >inet_daddr;
 		if(opt && opt >srr)
 			daddr = opt >faddr;
 
 		/* If this fails, retransmit mechanism of transport layer will
 		 * keep trying until route appears or the connection times
 	skb_dst_set_noref(skb, &rt >dst);
 
 packet_routed:
 	if (opt && opt >is_strictroute && rt >rt_dst != rt >rt_gateway)
 		goto no_route;
 
 	/* OK, we know where to send it, allocate and build IP header. */
 	skb_push(skb, sizeof(struct iphdr)   (opt ? opt >optlen : 0));
 	skb_reset_network_header(skb);
 	iph = ip_hdr(skb);
 	*((__be16 *)iph) = htons((4 << 12) | (5 << 8) | (inet >tos & 0xff));
 	iph >daddr    = rt >rt_dst;
 	/* Transport layer set skb >h.foo itself. */
 
 	if (opt && opt >optlen) {
 		iph >ihl  = opt >optlen >> 2;
 		ip_options_build(skb, opt, inet >inet_daddr, rt, 0);
 	}
 
 	ip_select_ident_more(iph, &rt >dst, sk,
 			 struct ipcm_cookie *ipc, struct rtable **rtp)
 {
 	struct inet_sock *inet = inet_sk(sk);
 	struct ip_options *opt;
 	struct rtable *rt;
 
 	/*
 			if (unlikely(cork >opt == NULL))
 				return  ENOBUFS;
 		}
 		memcpy(cork >opt, opt, sizeof(struct ip_options)   opt >optlen);
 		cork >flags |= IPCORK_OPT;
 		cork >addr = ipc >addr;
 	}
 		   unsigned int len)
 {
 	struct inet_sock *inet = inet_sk(sk);
 	struct {
 		struct ip_options	opt;
 		char			data[40];
 	} replyopts;
 	struct ipcm_cookie ipc;
 	__be32 daddr;
 	struct rtable *rt = skb_rtable(skb);
 
 	if (ip_options_echo(&replyopts.opt, skb))
 		return;
 
 	daddr = ipc.addr = rt >rt_src;
 	ipc.opt = NULL;
 	ipc.tx_flags = 0;
 
 	if (replyopts.opt.optlen) {
 		ipc.opt = &replyopts.opt;
 
 		if (ipc.opt >srr)
 			daddr = replyopts.opt.faddr;
 	}
 
 	{
 }
 
 
 /*
  *	Socket option code for IP. This is the end of the line after any
  *	TCP,UDP etc options on an IP socket.
 	switch (optname) {
 	case IP_OPTIONS:
 	{
 		struct ip_options *opt = NULL;
 		if (optlen > 40)
 			goto e_inval;
 		err = ip_options_get_from_user(sock_net(sk), &opt,
 					       optval, optlen);
 		if (err)
 			break;
 		if (inet >is_icsk) {
 			struct inet_connection_sock *icsk = inet_csk(sk);
 #if defined(CONFIG_IPV6) || defined(CONFIG_IPV6_MODULE)
 			       (TCPF_LISTEN | TCPF_CLOSE)) &&
 			     inet >inet_daddr != LOOPBACK4_IPV6)) {
 #endif
 				if (inet >opt)
 					icsk >icsk_ext_hdr_len  = inet >opt >optlen;
 				if (opt)
 					icsk >icsk_ext_hdr_len  = opt >optlen;
 				icsk >icsk_sync_mss(sk, icsk >icsk_pmtu_cookie);
 #if defined(CONFIG_IPV6) || defined(CONFIG_IPV6_MODULE)
 			}
 #endif
 		}
 		opt = xchg(&inet >opt, opt);
 		kfree(opt);
 		break;
 	}
 	case IP_PKTINFO:
 	case IP_OPTIONS:
 	{
 		unsigned char optbuf[sizeof(struct ip_options) 40];
 		struct ip_options * opt = (struct ip_options *)optbuf;
 		opt >optlen = 0;
 		if (inet >opt)
 			memcpy(optbuf, inet >opt,
 			       sizeof(struct ip_options) 
 			       inet >opt >optlen);
 		release_sock(sk);
 
 		if (opt >optlen == 0)
 	__be32 saddr;
 	u8  tos;
 	int err;
 
 	err =  EMSGSIZE;
 	if (len > 0xFFFF)
 	saddr = ipc.addr;
 	ipc.addr = daddr;
 
 	if (!ipc.opt)
 		ipc.opt = inet >opt;
 
 	if (ipc.opt) {
 		err =  EINVAL;
 		 */
 		if (inet >hdrincl)
 			goto done;
 		if (ipc.opt >srr) {
 			if (!daddr)
 				goto done;
 			daddr = ipc.opt >faddr;
 		}
 	}
 	tos = RT_CONN_FLAGS(sk);
 	 * the ACK carries the same options again (see RFC1122 4.2.3.8)
 	 */
 	if (opt && opt >optlen) {
 		int opt_size = sizeof(struct ip_options)   opt >optlen;
 
 		ireq >opt = kmalloc(opt_size, GFP_ATOMIC);
 		if (ireq >opt != NULL && ip_options_echo(ireq >opt, skb)) {
 			kfree(ireq >opt);
 			ireq >opt = NULL;
 		}
 	struct flowi4 fl4;
 	struct rtable *rt;
 	int err;
 
 	if (addr_len < sizeof(struct sockaddr_in))
 		return  EINVAL;
 		return  EAFNOSUPPORT;
 
 	nexthop = daddr = usin >sin_addr.s_addr;
 	if (inet >opt && inet >opt >srr) {
 		if (!daddr)
 			return  EINVAL;
 		nexthop = inet >opt >faddr;
 	}
 
 	orig_sport = inet >inet_sport;
 		return  ENETUNREACH;
 	}
 
 	if (!inet >opt || !inet >opt >srr)
 		daddr = rt >rt_dst;
 
 	if (!inet >inet_saddr)
 	inet >inet_daddr = daddr;
 
 	inet_csk(sk) >icsk_ext_hdr_len = 0;
 	if (inet >opt)
 		inet_csk(sk) >icsk_ext_hdr_len = inet >opt >optlen;
 
 	tp >rx_opt.mss_clamp = TCP_MSS_DEFAULT;
 
 /*
  * Save and compile IPv4 options into the request_sock if needed.
  */
 static struct ip_options *tcp_v4_save_options(struct sock *sk,
 					      struct sk_buff *skb)
 {
 	struct ip_options *opt = &(IPCB(skb) >opt);
 	struct ip_options *dopt = NULL;
 
 	if (opt && opt >optlen) {
 		int opt_size = optlength(opt);
 		dopt = kmalloc(opt_size, GFP_ATOMIC);
 		if (dopt) {
 			if (ip_options_echo(dopt, skb)) {
 				kfree(dopt);
 				dopt = NULL;
 			}
 #ifdef CONFIG_TCP_MD5SIG
 	struct tcp_md5sig_key *key;
 #endif
 
 	if (sk_acceptq_is_full(sk))
 		goto exit_overflow;
 	newinet >inet_daddr   = ireq >rmt_addr;
 	newinet >inet_rcv_saddr = ireq >loc_addr;
 	newinet >inet_saddr	      = ireq >loc_addr;
 	newinet >opt	      = ireq >opt;
 	ireq >opt	      = NULL;
 	newinet >mc_index     = inet_iif(skb);
 	newinet >mc_ttl	      = ip_hdr(skb) >ttl;
 	inet_csk(newsk) >icsk_ext_hdr_len = 0;
 	if (newinet >opt)
 		inet_csk(newsk) >icsk_ext_hdr_len = newinet >opt >optlen;
 	newinet >inet_id = newtp >write_seq ^ jiffies;
 
 	tcp_mtup_init(newsk);
 	int corkreq = up >corkflag || msg >msg_flags&MSG_MORE;
 	int (*getfrag)(void *, char *, int, int, int, struct sk_buff *);
 	struct sk_buff *skb;
 
 	if (len > 0xFFFF)
 		return  EMSGSIZE;
 			free = 1;
 		connected = 0;
 	}
 	if (!ipc.opt)
 		ipc.opt = inet >opt;
 
 	saddr = ipc.addr;
 	ipc.addr = faddr = daddr;
 
 	if (ipc.opt && ipc.opt >srr) {
 		if (!daddr)
 			return  EINVAL;
 		faddr = ipc.opt >faddr;
 		connected = 0;
 	}
 	tos = RT_TOS(inet >tos);
 	if (sock_flag(sk, SOCK_LOCALROUTE) ||
 	    (msg >msg_flags & MSG_DONTROUTE) ||
 	    (ipc.opt && ipc.opt >is_strictroute)) {
 		tos |= RTO_ONLINK;
 		connected = 0;
 	}
 
 	   First: no IPv4 options.
 	 */
 	newinet >opt = NULL;
 	newnp >ipv6_fl_list = NULL;
 
 	/* Clone RX bits */
 	int rc;
 	struct l2tp_ip_sock *lsa = l2tp_ip_sk(sk);
 	struct inet_sock *inet = inet_sk(sk);
 	struct ip_options *opt = inet >opt;
 	struct rtable *rt = NULL;
 	int connected = 0;
 	__be32 daddr;
 		rt = (struct rtable *) __sk_dst_check(sk, 0);
 
 	if (rt == NULL) {
 		/* Use correct destination address if we have options. */
 		if (opt && opt >srr)
 			daddr = opt >faddr;
 
 		/* If this fails, retransmit mechanism of transport layer will
 		 * keep trying until route appears or the connection times
After patch : 
 	unsigned char	__data[0];
 };
 
 struct ip_options_rcu {
 	struct rcu_head rcu;
 	struct ip_options opt;
 };
 
 struct ip_options_data {
 	struct ip_options_rcu	opt;
 	char			data[40];
 };
 
 struct inet_request_sock {
 	struct request_sock	req;
 				acked	   : 1,
 				no_srccheck: 1;
 	kmemcheck_bitfield_end(flags);
 	struct ip_options_rcu	*opt;
 };
 
 static inline struct inet_request_sock *inet_rsk(const struct request_sock *sk)
 	__be16			inet_sport;
 	__u16			inet_id;
 
 	struct ip_options_rcu __rcu	*inet_opt;
 	__u8			tos;
 	__u8			min_ttl;
 	__u8			mc_ttl;
 struct ipcm_cookie {
 	__be32			addr;
 	int			oif;
 	struct ip_options_rcu	*opt;
 	__u8			tx_flags;
 };
 
 
 extern int		ip_build_and_send_pkt(struct sk_buff *skb, struct sock *sk,
 					      __be32 saddr, __be32 daddr,
 					      struct ip_options_rcu *opt);
 extern int		ip_rcv(struct sk_buff *skb, struct net_device *dev,
 			       struct packet_type *pt, struct net_device *orig_dev);
 extern int		ip_local_deliver(struct sk_buff *skb);
  *	Functions provided by ip_options.c
  */
 
 extern void ip_options_build(struct sk_buff *skb, struct ip_options *opt,
 			     __be32 daddr, struct rtable *rt, int is_frag);
 extern int ip_options_echo(struct ip_options *dopt, struct sk_buff *skb);
 extern void ip_options_fragment(struct sk_buff *skb);
 extern int ip_options_compile(struct net *net,
 			      struct ip_options *opt, struct sk_buff *skb);
 extern int ip_options_get(struct net *net, struct ip_options_rcu **optp,
 			  unsigned char *data, int optlen);
 extern int ip_options_get_from_user(struct net *net, struct ip_options_rcu **optp,
 				    unsigned char __user *data, int optlen);
 extern void ip_options_undo(struct ip_options * opt);
 extern void ip_forward_options(struct sk_buff *skb);
 	struct flowi4 fl4;
 	struct rtable *rt;
 	int err;
 	struct ip_options_rcu *inet_opt;
 
 	dp >dccps_role = DCCP_ROLE_CLIENT;
 
 		return  EAFNOSUPPORT;
 
 	nexthop = daddr = usin >sin_addr.s_addr;
 
 	inet_opt = rcu_dereference_protected(inet >inet_opt,
 					     sock_owned_by_user(sk));
 	if (inet_opt != NULL && inet_opt >opt.srr) {
 		if (daddr == 0)
 			return  EINVAL;
 		nexthop = inet_opt >opt.faddr;
 	}
 
 	orig_sport = inet >inet_sport;
 		return  ENETUNREACH;
 	}
 
 	if (inet_opt == NULL || !inet_opt >opt.srr)
 		daddr = rt >rt_dst;
 
 	if (inet >inet_saddr == 0)
 	inet >inet_daddr = daddr;
 
 	inet_csk(sk) >icsk_ext_hdr_len = 0;
 	if (inet_opt)
 		inet_csk(sk) >icsk_ext_hdr_len = inet_opt >opt.optlen;
 	/*
 	 * Socket identity is still unknown (sport may be zero).
 	 * However we set state to DCCP_REQUESTING and not releasing socket
 	newinet >inet_daddr	= ireq >rmt_addr;
 	newinet >inet_rcv_saddr = ireq >loc_addr;
 	newinet >inet_saddr	= ireq >loc_addr;
 	newinet >inet_opt	= ireq >opt;
 	ireq >opt	   = NULL;
 	newinet >mc_index  = inet_iif(skb);
 	newinet >mc_ttl	   = ip_hdr(skb) >ttl;
 
 	   First: no IPv4 options.
 	 */
 	newinet >inet_opt = NULL;
 
 	/* Clone RX bits */
 	newnp >rxopt.all = np >rxopt.all;
 	WARN_ON(sk >sk_wmem_queued);
 	WARN_ON(sk >sk_forward_alloc);
 
 	kfree(rcu_dereference_protected(inet >inet_opt, 1));
 	dst_release(rcu_dereference_check(sk >sk_dst_cache, 1));
 	sk_refcnt_debug_dec(sk);
 }
 	struct flowi4 fl4;
 	struct rtable *rt;
 	__be32 new_saddr;
 	struct ip_options_rcu *inet_opt;
 
 	inet_opt = rcu_dereference_protected(inet >inet_opt,
 					     sock_owned_by_user(sk));
 	if (inet_opt && inet_opt >opt.srr)
 		daddr = inet_opt >opt.faddr;
 
 	/* Query new route. */
 	rt = ip_route_connect(&fl4, daddr, 0, RT_CONN_FLAGS(sk),
 	struct inet_sock *inet = inet_sk(sk);
 	struct rtable *rt = (struct rtable *)__sk_dst_check(sk, 0);
 	__be32 daddr;
 	struct ip_options_rcu *inet_opt;
 	int err;
 
 	/* Route is OK, nothing to do. */
 		return 0;
 
 	/* Reroute. */
 	rcu_read_lock();
 	inet_opt = rcu_dereference(inet >inet_opt);
 	daddr = inet >inet_daddr;
 	if (inet_opt && inet_opt >opt.srr)
 		daddr = inet_opt >opt.faddr;
 	rcu_read_unlock();
 	rt = ip_route_output_ports(sock_net(sk), sk, daddr, inet >inet_saddr,
 				   inet >inet_dport, inet >inet_sport,
 				   sk >sk_protocol, RT_CONN_FLAGS(sk),
 	return CIPSO_V4_HDR_LEN   ret_val;
 }
 
 static void opt_kfree_rcu(struct rcu_head *head)
 {
 	kfree(container_of(head, struct ip_options_rcu, rcu));
 }
 
 /**
  * cipso_v4_sock_setattr   Add a CIPSO option to a socket
  * @sk: the socket
 	unsigned char *buf = NULL;
 	u32 buf_len;
 	u32 opt_len;
 	struct ip_options_rcu *old, *opt = NULL;
 	struct inet_sock *sk_inet;
 	struct inet_connection_sock *sk_conn;
 
 		ret_val =  ENOMEM;
 		goto socket_setattr_failure;
 	}
 	memcpy(opt >opt.__data, buf, buf_len);
 	opt >opt.optlen = opt_len;
 	opt >opt.cipso = sizeof(struct iphdr);
 	kfree(buf);
 	buf = NULL;
 
 	sk_inet = inet_sk(sk);
 
 	old = rcu_dereference_protected(sk_inet >inet_opt, sock_owned_by_user(sk));
 	if (sk_inet >is_icsk) {
 		sk_conn = inet_csk(sk);
 		if (old)
 			sk_conn >icsk_ext_hdr_len  = old >opt.optlen;
 		sk_conn >icsk_ext_hdr_len  = opt >opt.optlen;
 		sk_conn >icsk_sync_mss(sk, sk_conn >icsk_pmtu_cookie);
 	}
 	rcu_assign_pointer(sk_inet >inet_opt, opt);
 	if (old)
 		call_rcu(&old >rcu, opt_kfree_rcu);
 
 	return 0;
 
 	unsigned char *buf = NULL;
 	u32 buf_len;
 	u32 opt_len;
 	struct ip_options_rcu *opt = NULL;
 	struct inet_request_sock *req_inet;
 
 	/* We allocate the maximum CIPSO option size here so we are probably
 		ret_val =  ENOMEM;
 		goto req_setattr_failure;
 	}
 	memcpy(opt >opt.__data, buf, buf_len);
 	opt >opt.optlen = opt_len;
 	opt >opt.cipso = sizeof(struct iphdr);
 	kfree(buf);
 	buf = NULL;
 
 	req_inet = inet_rsk(req);
 	opt = xchg(&req_inet >opt, opt);
 	if (opt)
 		call_rcu(&opt >rcu, opt_kfree_rcu);
 
 	return 0;
 
  * values on failure.
  *
  */
 static int cipso_v4_delopt(struct ip_options_rcu **opt_ptr)
 {
 	int hdr_delta = 0;
 	struct ip_options_rcu *opt = *opt_ptr;
 
 	if (opt >opt.srr || opt >opt.rr || opt >opt.ts || opt >opt.router_alert) {
 		u8 cipso_len;
 		u8 cipso_off;
 		unsigned char *cipso_ptr;
 		int iter;
 		int optlen_new;
 
 		cipso_off = opt >opt.cipso   sizeof(struct iphdr);
 		cipso_ptr = &opt >opt.__data[cipso_off];
 		cipso_len = cipso_ptr[1];
 
 		if (opt >opt.srr > opt >opt.cipso)
 			opt >opt.srr  = cipso_len;
 		if (opt >opt.rr > opt >opt.cipso)
 			opt >opt.rr  = cipso_len;
 		if (opt >opt.ts > opt >opt.cipso)
 			opt >opt.ts  = cipso_len;
 		if (opt >opt.router_alert > opt >opt.cipso)
 			opt >opt.router_alert  = cipso_len;
 		opt >opt.cipso = 0;
 
 		memmove(cipso_ptr, cipso_ptr   cipso_len,
 			opt >opt.optlen   cipso_off   cipso_len);
 
 		/* determining the new total option length is tricky because of
 		 * the padding necessary, the only thing i can think to do at
 		 * from there we can determine the new total option length */
 		iter = 0;
 		optlen_new = 0;
 		while (iter < opt >opt.optlen)
 			if (opt >opt.__data[iter] != IPOPT_NOP) {
 				iter  = opt >opt.__data[iter   1];
 				optlen_new = iter;
 			} else
 				iter  ;
 		hdr_delta = opt >opt.optlen;
 		opt >opt.optlen = (optlen_new   3) & ~3;
 		hdr_delta  = opt >opt.optlen;
 	} else {
 		/* only the cipso option was present on the socket so we can
 		 * remove the entire option struct */
 		*opt_ptr = NULL;
 		hdr_delta = opt >opt.optlen;
 		call_rcu(&opt >rcu, opt_kfree_rcu);
 	}
 
 	return hdr_delta;
 void cipso_v4_sock_delattr(struct sock *sk)
 {
 	int hdr_delta;
 	struct ip_options_rcu *opt;
 	struct inet_sock *sk_inet;
 
 	sk_inet = inet_sk(sk);
 	opt = rcu_dereference_protected(sk_inet >inet_opt, 1);
 	if (opt == NULL || opt >opt.cipso == 0)
 		return;
 
 	hdr_delta = cipso_v4_delopt(&sk_inet >inet_opt);
 	if (sk_inet >is_icsk && hdr_delta > 0) {
 		struct inet_connection_sock *sk_conn = inet_csk(sk);
 		sk_conn >icsk_ext_hdr_len  = hdr_delta;
  */
 void cipso_v4_req_delattr(struct request_sock *req)
 {
 	struct ip_options_rcu *opt;
 	struct inet_request_sock *req_inet;
 
 	req_inet = inet_rsk(req);
 	opt = req_inet >opt;
 	if (opt == NULL || opt >opt.cipso == 0)
 		return;
 
 	cipso_v4_delopt(&req_inet >opt);
  */
 int cipso_v4_sock_getattr(struct sock *sk, struct netlbl_lsm_secattr *secattr)
 {
 	struct ip_options_rcu *opt;
 	int res =  ENOMSG;
 
 	rcu_read_lock();
 	opt = rcu_dereference(inet_sk(sk) >inet_opt);
 	if (opt && opt >opt.cipso)
 		res = cipso_v4_getattr(opt >opt.__data  
 						opt >opt.cipso  
 						sizeof(struct iphdr),
 				       secattr);
 	rcu_read_unlock();
 	return res;
 }
 
 /**
 		__be32	       times[3];
 	} data;
 	int head_len;
 	struct ip_options_data replyopts;
 };
 
 /* An array of errno for error messages from dest unreach. */
 	struct inet_sock *inet;
 	__be32 daddr;
 
 	if (ip_options_echo(&icmp_param >replyopts.opt.opt, skb))
 		return;
 
 	sk = icmp_xmit_lock(net);
 	daddr = ipc.addr = rt >rt_src;
 	ipc.opt = NULL;
 	ipc.tx_flags = 0;
 	if (icmp_param >replyopts.opt.opt.optlen) {
 		ipc.opt = &icmp_param >replyopts.opt;
 		if (ipc.opt >opt.srr)
 			daddr = icmp_param >replyopts.opt.opt.faddr;
 	}
 	{
 		struct flowi4 fl4 = {
 					struct icmp_bxm *param)
 {
 	struct flowi4 fl4 = {
 		.daddr = (param >replyopts.opt.opt.srr ?
 			  param >replyopts.opt.opt.faddr : iph >saddr),
 		.saddr = saddr,
 		.flowi4_tos = RT_TOS(tos),
 		.flowi4_proto = IPPROTO_ICMP,
 					   IPTOS_PREC_INTERNETCONTROL) :
 					  iph >tos;
 
 	if (ip_options_echo(&icmp_param.replyopts.opt.opt, skb_in))
 		goto out_unlock;
 
 
 	icmp_param.offset = skb_network_offset(skb_in);
 	inet_sk(sk) >tos = tos;
 	ipc.addr = iph >saddr;
 	ipc.opt = &icmp_param.replyopts.opt;
 	ipc.tx_flags = 0;
 
 	rt = icmp_route_lookup(net, skb_in, iph, saddr, tos,
 	room = dst_mtu(&rt >dst);
 	if (room > 576)
 		room = 576;
 	room  = sizeof(struct iphdr)   icmp_param.replyopts.opt.opt.optlen;
 	room  = sizeof(struct icmphdr);
 
 	icmp_param.data_len = skb_in >len   icmp_param.offset;
 {
 	struct rtable *rt;
 	const struct inet_request_sock *ireq = inet_rsk(req);
 	struct ip_options_rcu *opt = inet_rsk(req) >opt;
 	struct net *net = sock_net(sk);
 	struct flowi4 fl4;
 
 	flowi4_init_output(&fl4, sk >sk_bound_dev_if, sk >sk_mark,
 			   RT_CONN_FLAGS(sk), RT_SCOPE_UNIVERSE,
 			   sk >sk_protocol, inet_sk_flowi_flags(sk),
 			   (opt && opt >opt.srr) ? opt >opt.faddr : ireq >rmt_addr,
 			   ireq >loc_addr, ireq >rmt_port, inet_sk(sk) >inet_sport);
 	security_req_classify_flow(req, flowi4_to_flowi(&fl4));
 	rt = ip_route_output_flow(net, &fl4, sk);
 	if (IS_ERR(rt))
 		goto no_route;
 	if (opt && opt >opt.is_strictroute && rt >rt_dst != rt >rt_gateway)
 		goto route_err;
 	return &rt >dst;
 
  * saddr is address of outgoing interface.
  */
 
 void ip_options_build(struct sk_buff *skb, struct ip_options *opt,
 			    __be32 daddr, struct rtable *rt, int is_frag)
 {
 	unsigned char *iph = skb_network_header(skb);
  * NOTE: dopt cannot point to skb.
  */
 
 int ip_options_echo(struct ip_options *dopt, struct sk_buff *skb)
 {
 	const struct ip_options *sopt;
 	unsigned char *sptr, *dptr;
 	int soffset, doffset;
 	int	optlen;
 
 	sopt = &(IPCB(skb) >opt);
 
 	if (sopt >optlen == 0)
 		return 0;
 
 	sptr = skb_network_header(skb);
 	dptr = dopt >__data;
 		dopt >optlen  = optlen;
 	}
 	if (sopt >srr) {
 		unsigned char *start = sptr sopt >srr;
 		__be32 faddr;
 
 		optlen  = start[1];
 	}
 }
 
 static struct ip_options_rcu *ip_options_get_alloc(const int optlen)
 {
 	return kzalloc(sizeof(struct ip_options_rcu)   ((optlen   3) & ~3),
 		       GFP_KERNEL);
 }
 
 static int ip_options_get_finish(struct net *net, struct ip_options_rcu **optp,
 				 struct ip_options_rcu *opt, int optlen)
 {
 	while (optlen & 3)
 		opt >opt.__data[optlen  ] = IPOPT_END;
 	opt >opt.optlen = optlen;
 	if (optlen && ip_options_compile(net, &opt >opt, NULL)) {
 		kfree(opt);
 		return  EINVAL;
 	}
 	return 0;
 }
 
 int ip_options_get_from_user(struct net *net, struct ip_options_rcu **optp,
 			     unsigned char __user *data, int optlen)
 {
 	struct ip_options_rcu *opt = ip_options_get_alloc(optlen);
 
 	if (!opt)
 		return  ENOMEM;
 	if (optlen && copy_from_user(opt >opt.__data, data, optlen)) {
 		kfree(opt);
 		return  EFAULT;
 	}
 	return ip_options_get_finish(net, optp, opt, optlen);
 }
 
 int ip_options_get(struct net *net, struct ip_options_rcu **optp,
 		   unsigned char *data, int optlen)
 {
 	struct ip_options_rcu *opt = ip_options_get_alloc(optlen);
 
 	if (!opt)
 		return  ENOMEM;
 	if (optlen)
 		memcpy(opt >opt.__data, data, optlen);
 	return ip_options_get_finish(net, optp, opt, optlen);
 }
 
  *
  */
 int ip_build_and_send_pkt(struct sk_buff *skb, struct sock *sk,
 			  __be32 saddr, __be32 daddr, struct ip_options_rcu *opt)
 {
 	struct inet_sock *inet = inet_sk(sk);
 	struct rtable *rt = skb_rtable(skb);
 	struct iphdr *iph;
 
 	/* Build the IP header. */
 	skb_push(skb, sizeof(struct iphdr)   (opt ? opt >opt.optlen : 0));
 	skb_reset_network_header(skb);
 	iph = ip_hdr(skb);
 	iph >version  = 4;
 	iph >protocol = sk >sk_protocol;
 	ip_select_ident(iph, &rt >dst, sk);
 
 	if (opt && opt >opt.optlen) {
 		iph >ihl  = opt >opt.optlen>>2;
 		ip_options_build(skb, &opt >opt, daddr, rt, 0);
 	}
 
 	skb >priority = sk >sk_priority;
 {
 	struct sock *sk = skb >sk;
 	struct inet_sock *inet = inet_sk(sk);
 	struct ip_options_rcu *inet_opt;
 	struct rtable *rt;
 	struct iphdr *iph;
 	int res;
 	 * f.e. by something like SCTP.
 	 */
 	rcu_read_lock();
 	inet_opt = rcu_dereference(inet >inet_opt);
 	rt = skb_rtable(skb);
 	if (rt != NULL)
 		goto packet_routed;
 
 		/* Use correct destination address if we have options. */
 		daddr = inet >inet_daddr;
 		if (inet_opt && inet_opt >opt.srr)
 			daddr = inet_opt >opt.faddr;
 
 		/* If this fails, retransmit mechanism of transport layer will
 		 * keep trying until route appears or the connection times
 	skb_dst_set_noref(skb, &rt >dst);
 
 packet_routed:
 	if (inet_opt && inet_opt >opt.is_strictroute && rt >rt_dst != rt >rt_gateway)
 		goto no_route;
 
 	/* OK, we know where to send it, allocate and build IP header. */
 	skb_push(skb, sizeof(struct iphdr)   (inet_opt ? inet_opt >opt.optlen : 0));
 	skb_reset_network_header(skb);
 	iph = ip_hdr(skb);
 	*((__be16 *)iph) = htons((4 << 12) | (5 << 8) | (inet >tos & 0xff));
 	iph >daddr    = rt >rt_dst;
 	/* Transport layer set skb >h.foo itself. */
 
 	if (inet_opt && inet_opt >opt.optlen) {
 		iph >ihl  = inet_opt >opt.optlen >> 2;
 		ip_options_build(skb, &inet_opt >opt, inet >inet_daddr, rt, 0);
 	}
 
 	ip_select_ident_more(iph, &rt >dst, sk,
 			 struct ipcm_cookie *ipc, struct rtable **rtp)
 {
 	struct inet_sock *inet = inet_sk(sk);
 	struct ip_options_rcu *opt;
 	struct rtable *rt;
 
 	/*
 			if (unlikely(cork >opt == NULL))
 				return  ENOBUFS;
 		}
 		memcpy(cork >opt, &opt >opt, sizeof(struct ip_options)   opt >opt.optlen);
 		cork >flags |= IPCORK_OPT;
 		cork >addr = ipc >addr;
 	}
 		   unsigned int len)
 {
 	struct inet_sock *inet = inet_sk(sk);
 	struct ip_options_data replyopts;
 	struct ipcm_cookie ipc;
 	__be32 daddr;
 	struct rtable *rt = skb_rtable(skb);
 
 	if (ip_options_echo(&replyopts.opt.opt, skb))
 		return;
 
 	daddr = ipc.addr = rt >rt_src;
 	ipc.opt = NULL;
 	ipc.tx_flags = 0;
 
 	if (replyopts.opt.opt.optlen) {
 		ipc.opt = &replyopts.opt;
 
 		if (replyopts.opt.opt.srr)
 			daddr = replyopts.opt.opt.faddr;
 	}
 
 	{
 }
 
 
 static void opt_kfree_rcu(struct rcu_head *head)
 {
 	kfree(container_of(head, struct ip_options_rcu, rcu));
 }
 
 /*
  *	Socket option code for IP. This is the end of the line after any
  *	TCP,UDP etc options on an IP socket.
 	switch (optname) {
 	case IP_OPTIONS:
 	{
 		struct ip_options_rcu *old, *opt = NULL;
 
 		if (optlen > 40)
 			goto e_inval;
 		err = ip_options_get_from_user(sock_net(sk), &opt,
 					       optval, optlen);
 		if (err)
 			break;
 		old = rcu_dereference_protected(inet >inet_opt,
 						sock_owned_by_user(sk));
 		if (inet >is_icsk) {
 			struct inet_connection_sock *icsk = inet_csk(sk);
 #if defined(CONFIG_IPV6) || defined(CONFIG_IPV6_MODULE)
 			       (TCPF_LISTEN | TCPF_CLOSE)) &&
 			     inet >inet_daddr != LOOPBACK4_IPV6)) {
 #endif
 				if (old)
 					icsk >icsk_ext_hdr_len  = old >opt.optlen;
 				if (opt)
 					icsk >icsk_ext_hdr_len  = opt >opt.optlen;
 				icsk >icsk_sync_mss(sk, icsk >icsk_pmtu_cookie);
 #if defined(CONFIG_IPV6) || defined(CONFIG_IPV6_MODULE)
 			}
 #endif
 		}
 		rcu_assign_pointer(inet >inet_opt, opt);
 		if (old)
 			call_rcu(&old >rcu, opt_kfree_rcu);
 		break;
 	}
 	case IP_PKTINFO:
 	case IP_OPTIONS:
 	{
 		unsigned char optbuf[sizeof(struct ip_options) 40];
 		struct ip_options *opt = (struct ip_options *)optbuf;
 		struct ip_options_rcu *inet_opt;
 
 		inet_opt = rcu_dereference_protected(inet >inet_opt,
 						     sock_owned_by_user(sk));
 		opt >optlen = 0;
 		if (inet_opt)
 			memcpy(optbuf, &inet_opt >opt,
 			       sizeof(struct ip_options)  
 			       inet_opt >opt.optlen);
 		release_sock(sk);
 
 		if (opt >optlen == 0)
 	__be32 saddr;
 	u8  tos;
 	int err;
 	struct ip_options_data opt_copy;
 
 	err =  EMSGSIZE;
 	if (len > 0xFFFF)
 	saddr = ipc.addr;
 	ipc.addr = daddr;
 
 	if (!ipc.opt) {
 		struct ip_options_rcu *inet_opt;
 
 		rcu_read_lock();
 		inet_opt = rcu_dereference(inet >inet_opt);
 		if (inet_opt) {
 			memcpy(&opt_copy, inet_opt,
 			       sizeof(*inet_opt)   inet_opt >opt.optlen);
 			ipc.opt = &opt_copy.opt;
 		}
 		rcu_read_unlock();
 	}
 
 	if (ipc.opt) {
 		err =  EINVAL;
 		 */
 		if (inet >hdrincl)
 			goto done;
 		if (ipc.opt >opt.srr) {
 			if (!daddr)
 				goto done;
 			daddr = ipc.opt >opt.faddr;
 		}
 	}
 	tos = RT_CONN_FLAGS(sk);
 	 * the ACK carries the same options again (see RFC1122 4.2.3.8)
 	 */
 	if (opt && opt >optlen) {
 		int opt_size = sizeof(struct ip_options_rcu)   opt >optlen;
 
 		ireq >opt = kmalloc(opt_size, GFP_ATOMIC);
 		if (ireq >opt != NULL && ip_options_echo(&ireq >opt >opt, skb)) {
 			kfree(ireq >opt);
 			ireq >opt = NULL;
 		}
 	struct flowi4 fl4;
 	struct rtable *rt;
 	int err;
 	struct ip_options_rcu *inet_opt;
 
 	if (addr_len < sizeof(struct sockaddr_in))
 		return  EINVAL;
 		return  EAFNOSUPPORT;
 
 	nexthop = daddr = usin >sin_addr.s_addr;
 	inet_opt = rcu_dereference_protected(inet >inet_opt,
 					     sock_owned_by_user(sk));
 	if (inet_opt && inet_opt >opt.srr) {
 		if (!daddr)
 			return  EINVAL;
 		nexthop = inet_opt >opt.faddr;
 	}
 
 	orig_sport = inet >inet_sport;
 		return  ENETUNREACH;
 	}
 
 	if (!inet_opt || !inet_opt >opt.srr)
 		daddr = rt >rt_dst;
 
 	if (!inet >inet_saddr)
 	inet >inet_daddr = daddr;
 
 	inet_csk(sk) >icsk_ext_hdr_len = 0;
 	if (inet_opt)
 		inet_csk(sk) >icsk_ext_hdr_len = inet_opt >opt.optlen;
 
 	tp >rx_opt.mss_clamp = TCP_MSS_DEFAULT;
 
 /*
  * Save and compile IPv4 options into the request_sock if needed.
  */
 static struct ip_options_rcu *tcp_v4_save_options(struct sock *sk,
 						  struct sk_buff *skb)
 {
 	const struct ip_options *opt = &(IPCB(skb) >opt);
 	struct ip_options_rcu *dopt = NULL;
 
 	if (opt && opt >optlen) {
 		int opt_size = sizeof(*dopt)   opt >optlen;
 
 		dopt = kmalloc(opt_size, GFP_ATOMIC);
 		if (dopt) {
 			if (ip_options_echo(&dopt >opt, skb)) {
 				kfree(dopt);
 				dopt = NULL;
 			}
 #ifdef CONFIG_TCP_MD5SIG
 	struct tcp_md5sig_key *key;
 #endif
 	struct ip_options_rcu *inet_opt;
 
 	if (sk_acceptq_is_full(sk))
 		goto exit_overflow;
 	newinet >inet_daddr   = ireq >rmt_addr;
 	newinet >inet_rcv_saddr = ireq >loc_addr;
 	newinet >inet_saddr	      = ireq >loc_addr;
 	inet_opt	      = ireq >opt;
 	rcu_assign_pointer(newinet >inet_opt, inet_opt);
 	ireq >opt	      = NULL;
 	newinet >mc_index     = inet_iif(skb);
 	newinet >mc_ttl	      = ip_hdr(skb) >ttl;
 	inet_csk(newsk) >icsk_ext_hdr_len = 0;
 	if (inet_opt)
 		inet_csk(newsk) >icsk_ext_hdr_len = inet_opt >opt.optlen;
 	newinet >inet_id = newtp >write_seq ^ jiffies;
 
 	tcp_mtup_init(newsk);
 	int corkreq = up >corkflag || msg >msg_flags&MSG_MORE;
 	int (*getfrag)(void *, char *, int, int, int, struct sk_buff *);
 	struct sk_buff *skb;
 	struct ip_options_data opt_copy;
 
 	if (len > 0xFFFF)
 		return  EMSGSIZE;
 			free = 1;
 		connected = 0;
 	}
 	if (!ipc.opt) {
 		struct ip_options_rcu *inet_opt;
 
 		rcu_read_lock();
 		inet_opt = rcu_dereference(inet >inet_opt);
 		if (inet_opt) {
 			memcpy(&opt_copy, inet_opt,
 			       sizeof(*inet_opt)   inet_opt >opt.optlen);
 			ipc.opt = &opt_copy.opt;
 		}
 		rcu_read_unlock();
 	}
 
 	saddr = ipc.addr;
 	ipc.addr = faddr = daddr;
 
 	if (ipc.opt && ipc.opt >opt.srr) {
 		if (!daddr)
 			return  EINVAL;
 		faddr = ipc.opt >opt.faddr;
 		connected = 0;
 	}
 	tos = RT_TOS(inet >tos);
 	if (sock_flag(sk, SOCK_LOCALROUTE) ||
 	    (msg >msg_flags & MSG_DONTROUTE) ||
 	    (ipc.opt && ipc.opt >opt.is_strictroute)) {
 		tos |= RTO_ONLINK;
 		connected = 0;
 	}
 
 	   First: no IPv4 options.
 	 */
 	newinet >inet_opt = NULL;
 	newnp >ipv6_fl_list = NULL;
 
 	/* Clone RX bits */
 	int rc;
 	struct l2tp_ip_sock *lsa = l2tp_ip_sk(sk);
 	struct inet_sock *inet = inet_sk(sk);
 	struct rtable *rt = NULL;
 	int connected = 0;
 	__be32 daddr;
 		rt = (struct rtable *) __sk_dst_check(sk, 0);
 
 	if (rt == NULL) {
 		struct ip_options_rcu *inet_opt;
 
 		inet_opt = rcu_dereference_protected(inet >inet_opt,
 						     sock_owned_by_user(sk));
 
 		/* Use correct destination address if we have options. */
 		if (inet_opt && inet_opt >opt.srr)
 			daddr = inet_opt >opt.faddr;
 
 		/* If this fails, retransmit mechanism of transport layer will
 		 * keep trying until route appears or the connection times
